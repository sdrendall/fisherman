Log file created at: 2016/06/30 12:08:33
Running on machine: betty
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0630 12:08:33.353444 30262 caffe.cpp:185] Using GPUs 0
I0630 12:08:33.419512 30262 caffe.cpp:190] GPU 0: GeForce GTX 760
I0630 12:08:34.057343 30262 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 500
base_lr: 0.001
display: 25
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.4
weight_decay: 0.0005
snapshot: 1000
snapshot_prefix: "fish_net_pretrain_output"
solver_mode: GPU
device_id: 0
net: "/home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_pretrainer.prototxt"
I0630 12:08:34.057576 30262 solver.cpp:91] Creating training net from net file: /home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_pretrainer.prototxt
I0630 12:08:34.057916 30262 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer testing_cells
I0630 12:08:34.057945 30262 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0630 12:08:34.058015 30262 net.cpp:49] Initializing net from parameters: 
name: "fish_filter"
state {
  phase: TRAIN
}
layer {
  name: "training_cells"
  type: "Data"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/sam/code/fisherman/data/original_and_partial_qc_2_channel_k149_scaled/training_db"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "image"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 15
    kernel_size: 15
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 5
    stride: 5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0630 12:08:34.058353 30262 layer_factory.hpp:77] Creating layer training_cells
I0630 12:08:34.058908 30262 net.cpp:91] Creating Layer training_cells
I0630 12:08:34.058922 30262 net.cpp:399] training_cells -> image
I0630 12:08:34.058944 30262 net.cpp:399] training_cells -> label
I0630 12:08:34.061143 30274 db_lmdb.cpp:35] Opened lmdb /home/sam/code/fisherman/data/original_and_partial_qc_2_channel_k149_scaled/training_db
I0630 12:08:34.218713 30262 data_layer.cpp:41] output data size: 256,2,149,149
I0630 12:08:34.308784 30262 net.cpp:141] Setting up training_cells
I0630 12:08:34.308817 30262 net.cpp:148] Top shape: 256 2 149 149 (11366912)
I0630 12:08:34.308826 30262 net.cpp:148] Top shape: 256 (256)
I0630 12:08:34.308831 30262 net.cpp:156] Memory required for data: 45468672
I0630 12:08:34.308842 30262 layer_factory.hpp:77] Creating layer conv1
I0630 12:08:34.308862 30262 net.cpp:91] Creating Layer conv1
I0630 12:08:34.308876 30262 net.cpp:425] conv1 <- image
I0630 12:08:34.308889 30262 net.cpp:399] conv1 -> conv1
I0630 12:08:34.313529 30262 net.cpp:141] Setting up conv1
I0630 12:08:34.313546 30262 net.cpp:148] Top shape: 256 15 135 135 (69984000)
I0630 12:08:34.313552 30262 net.cpp:156] Memory required for data: 325404672
I0630 12:08:34.313567 30262 layer_factory.hpp:77] Creating layer pool1
I0630 12:08:34.313578 30262 net.cpp:91] Creating Layer pool1
I0630 12:08:34.313583 30262 net.cpp:425] pool1 <- conv1
I0630 12:08:34.313591 30262 net.cpp:399] pool1 -> pool1
I0630 12:08:34.326110 30262 net.cpp:141] Setting up pool1
I0630 12:08:34.326130 30262 net.cpp:148] Top shape: 256 15 27 27 (2799360)
I0630 12:08:34.326136 30262 net.cpp:156] Memory required for data: 336602112
I0630 12:08:34.326151 30262 layer_factory.hpp:77] Creating layer conv2
I0630 12:08:34.326166 30262 net.cpp:91] Creating Layer conv2
I0630 12:08:34.326175 30262 net.cpp:425] conv2 <- pool1
I0630 12:08:34.326190 30262 net.cpp:399] conv2 -> conv2
I0630 12:08:34.333232 30262 net.cpp:141] Setting up conv2
I0630 12:08:34.333281 30262 net.cpp:148] Top shape: 256 5 21 21 (564480)
I0630 12:08:34.333286 30262 net.cpp:156] Memory required for data: 338860032
I0630 12:08:34.333300 30262 layer_factory.hpp:77] Creating layer pool2
I0630 12:08:34.333317 30262 net.cpp:91] Creating Layer pool2
I0630 12:08:34.333323 30262 net.cpp:425] pool2 <- conv2
I0630 12:08:34.333333 30262 net.cpp:399] pool2 -> pool2
I0630 12:08:34.333367 30262 net.cpp:141] Setting up pool2
I0630 12:08:34.333375 30262 net.cpp:148] Top shape: 256 5 7 7 (62720)
I0630 12:08:34.333379 30262 net.cpp:156] Memory required for data: 339110912
I0630 12:08:34.333384 30262 layer_factory.hpp:77] Creating layer ip1
I0630 12:08:34.333395 30262 net.cpp:91] Creating Layer ip1
I0630 12:08:34.333400 30262 net.cpp:425] ip1 <- pool2
I0630 12:08:34.333406 30262 net.cpp:399] ip1 -> ip1
I0630 12:08:34.333536 30262 net.cpp:141] Setting up ip1
I0630 12:08:34.333544 30262 net.cpp:148] Top shape: 256 32 (8192)
I0630 12:08:34.333549 30262 net.cpp:156] Memory required for data: 339143680
I0630 12:08:34.333557 30262 layer_factory.hpp:77] Creating layer relu1
I0630 12:08:34.333564 30262 net.cpp:91] Creating Layer relu1
I0630 12:08:34.333570 30262 net.cpp:425] relu1 <- ip1
I0630 12:08:34.333576 30262 net.cpp:386] relu1 -> ip1 (in-place)
I0630 12:08:34.333588 30262 net.cpp:141] Setting up relu1
I0630 12:08:34.333601 30262 net.cpp:148] Top shape: 256 32 (8192)
I0630 12:08:34.333606 30262 net.cpp:156] Memory required for data: 339176448
I0630 12:08:34.333611 30262 layer_factory.hpp:77] Creating layer drop1
I0630 12:08:34.333629 30262 net.cpp:91] Creating Layer drop1
I0630 12:08:34.333636 30262 net.cpp:425] drop1 <- ip1
I0630 12:08:34.333642 30262 net.cpp:386] drop1 -> ip1 (in-place)
I0630 12:08:34.333665 30262 net.cpp:141] Setting up drop1
I0630 12:08:34.333673 30262 net.cpp:148] Top shape: 256 32 (8192)
I0630 12:08:34.333678 30262 net.cpp:156] Memory required for data: 339209216
I0630 12:08:34.333681 30262 layer_factory.hpp:77] Creating layer ip2
I0630 12:08:34.333690 30262 net.cpp:91] Creating Layer ip2
I0630 12:08:34.333695 30262 net.cpp:425] ip2 <- ip1
I0630 12:08:34.333703 30262 net.cpp:399] ip2 -> ip2
I0630 12:08:34.333765 30262 net.cpp:141] Setting up ip2
I0630 12:08:34.333773 30262 net.cpp:148] Top shape: 256 2 (512)
I0630 12:08:34.333777 30262 net.cpp:156] Memory required for data: 339211264
I0630 12:08:34.333784 30262 layer_factory.hpp:77] Creating layer loss
I0630 12:08:34.333791 30262 net.cpp:91] Creating Layer loss
I0630 12:08:34.333797 30262 net.cpp:425] loss <- ip2
I0630 12:08:34.333802 30262 net.cpp:425] loss <- label
I0630 12:08:34.333809 30262 net.cpp:399] loss -> loss
I0630 12:08:34.333823 30262 layer_factory.hpp:77] Creating layer loss
I0630 12:08:34.333880 30262 net.cpp:141] Setting up loss
I0630 12:08:34.333889 30262 net.cpp:148] Top shape: (1)
I0630 12:08:34.333892 30262 net.cpp:151]     with loss weight 1
I0630 12:08:34.333917 30262 net.cpp:156] Memory required for data: 339211268
I0630 12:08:34.333922 30262 net.cpp:217] loss needs backward computation.
I0630 12:08:34.333927 30262 net.cpp:217] ip2 needs backward computation.
I0630 12:08:34.334002 30262 net.cpp:217] drop1 needs backward computation.
I0630 12:08:34.334007 30262 net.cpp:217] relu1 needs backward computation.
I0630 12:08:34.334010 30262 net.cpp:217] ip1 needs backward computation.
I0630 12:08:34.334015 30262 net.cpp:217] pool2 needs backward computation.
I0630 12:08:34.334019 30262 net.cpp:217] conv2 needs backward computation.
I0630 12:08:34.334024 30262 net.cpp:217] pool1 needs backward computation.
I0630 12:08:34.334029 30262 net.cpp:217] conv1 needs backward computation.
I0630 12:08:34.334034 30262 net.cpp:219] training_cells does not need backward computation.
I0630 12:08:34.334038 30262 net.cpp:261] This network produces output loss
I0630 12:08:34.334048 30262 net.cpp:274] Network initialization done.
I0630 12:08:34.334460 30262 solver.cpp:181] Creating test net (#0) specified by net file: /home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_pretrainer.prototxt
I0630 12:08:34.334497 30262 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer training_cells
I0630 12:08:34.334511 30262 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer drop1
I0630 12:08:34.334604 30262 net.cpp:49] Initializing net from parameters: 
name: "fish_filter"
state {
  phase: TEST
}
layer {
  name: "testing_cells"
  type: "Data"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/sam/code/fisherman/data/original_and_partial_qc_2_channel_k149_scaled/testing_db"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "image"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 15
    kernel_size: 15
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 5
    stride: 5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0630 12:08:34.334915 30262 layer_factory.hpp:77] Creating layer testing_cells
I0630 12:08:34.335108 30262 net.cpp:91] Creating Layer testing_cells
I0630 12:08:34.335117 30262 net.cpp:399] testing_cells -> image
I0630 12:08:34.335129 30262 net.cpp:399] testing_cells -> label
I0630 12:08:34.337000 30276 db_lmdb.cpp:35] Opened lmdb /home/sam/code/fisherman/data/original_and_partial_qc_2_channel_k149_scaled/testing_db
I0630 12:08:34.338943 30262 data_layer.cpp:41] output data size: 256,2,149,149
I0630 12:08:34.490176 30262 net.cpp:141] Setting up testing_cells
I0630 12:08:34.490227 30262 net.cpp:148] Top shape: 256 2 149 149 (11366912)
I0630 12:08:34.490243 30262 net.cpp:148] Top shape: 256 (256)
I0630 12:08:34.490250 30262 net.cpp:156] Memory required for data: 45468672
I0630 12:08:34.490339 30262 layer_factory.hpp:77] Creating layer label_testing_cells_1_split
I0630 12:08:34.490365 30262 net.cpp:91] Creating Layer label_testing_cells_1_split
I0630 12:08:34.490381 30262 net.cpp:425] label_testing_cells_1_split <- label
I0630 12:08:34.490396 30262 net.cpp:399] label_testing_cells_1_split -> label_testing_cells_1_split_0
I0630 12:08:34.490422 30262 net.cpp:399] label_testing_cells_1_split -> label_testing_cells_1_split_1
I0630 12:08:34.490495 30262 net.cpp:141] Setting up label_testing_cells_1_split
I0630 12:08:34.490512 30262 net.cpp:148] Top shape: 256 (256)
I0630 12:08:34.490520 30262 net.cpp:148] Top shape: 256 (256)
I0630 12:08:34.490528 30262 net.cpp:156] Memory required for data: 45470720
I0630 12:08:34.490537 30262 layer_factory.hpp:77] Creating layer conv1
I0630 12:08:34.490566 30262 net.cpp:91] Creating Layer conv1
I0630 12:08:34.490574 30262 net.cpp:425] conv1 <- image
I0630 12:08:34.490586 30262 net.cpp:399] conv1 -> conv1
I0630 12:08:34.490947 30262 net.cpp:141] Setting up conv1
I0630 12:08:34.490968 30262 net.cpp:148] Top shape: 256 15 135 135 (69984000)
I0630 12:08:34.490978 30262 net.cpp:156] Memory required for data: 325406720
I0630 12:08:34.490996 30262 layer_factory.hpp:77] Creating layer pool1
I0630 12:08:34.491016 30262 net.cpp:91] Creating Layer pool1
I0630 12:08:34.491026 30262 net.cpp:425] pool1 <- conv1
I0630 12:08:34.491041 30262 net.cpp:399] pool1 -> pool1
I0630 12:08:34.491108 30262 net.cpp:141] Setting up pool1
I0630 12:08:34.491123 30262 net.cpp:148] Top shape: 256 15 27 27 (2799360)
I0630 12:08:34.491132 30262 net.cpp:156] Memory required for data: 336604160
I0630 12:08:34.491138 30262 layer_factory.hpp:77] Creating layer conv2
I0630 12:08:34.491158 30262 net.cpp:91] Creating Layer conv2
I0630 12:08:34.491170 30262 net.cpp:425] conv2 <- pool1
I0630 12:08:34.491184 30262 net.cpp:399] conv2 -> conv2
I0630 12:08:34.524590 30262 net.cpp:141] Setting up conv2
I0630 12:08:34.526769 30262 net.cpp:148] Top shape: 256 5 21 21 (564480)
I0630 12:08:34.528759 30262 net.cpp:156] Memory required for data: 338862080
I0630 12:08:34.528792 30262 layer_factory.hpp:77] Creating layer pool2
I0630 12:08:34.528811 30262 net.cpp:91] Creating Layer pool2
I0630 12:08:34.528820 30262 net.cpp:425] pool2 <- conv2
I0630 12:08:34.528833 30262 net.cpp:399] pool2 -> pool2
I0630 12:08:34.532500 30262 net.cpp:141] Setting up pool2
I0630 12:08:34.532551 30262 net.cpp:148] Top shape: 256 5 7 7 (62720)
I0630 12:08:34.532559 30262 net.cpp:156] Memory required for data: 339112960
I0630 12:08:34.532568 30262 layer_factory.hpp:77] Creating layer ip1
I0630 12:08:34.532595 30262 net.cpp:91] Creating Layer ip1
I0630 12:08:34.532608 30262 net.cpp:425] ip1 <- pool2
I0630 12:08:34.532631 30262 net.cpp:399] ip1 -> ip1
I0630 12:08:34.534874 30262 net.cpp:141] Setting up ip1
I0630 12:08:34.535001 30262 net.cpp:148] Top shape: 256 32 (8192)
I0630 12:08:34.535058 30262 net.cpp:156] Memory required for data: 339145728
I0630 12:08:34.535122 30262 layer_factory.hpp:77] Creating layer relu1
I0630 12:08:34.535183 30262 net.cpp:91] Creating Layer relu1
I0630 12:08:34.535235 30262 net.cpp:425] relu1 <- ip1
I0630 12:08:34.535286 30262 net.cpp:386] relu1 -> ip1 (in-place)
I0630 12:08:34.535332 30262 net.cpp:141] Setting up relu1
I0630 12:08:34.535374 30262 net.cpp:148] Top shape: 256 32 (8192)
I0630 12:08:34.535413 30262 net.cpp:156] Memory required for data: 339178496
I0630 12:08:34.535450 30262 layer_factory.hpp:77] Creating layer ip2
I0630 12:08:34.535496 30262 net.cpp:91] Creating Layer ip2
I0630 12:08:34.535537 30262 net.cpp:425] ip2 <- ip1
I0630 12:08:34.536901 30262 net.cpp:399] ip2 -> ip2
I0630 12:08:34.537194 30262 net.cpp:141] Setting up ip2
I0630 12:08:34.537261 30262 net.cpp:148] Top shape: 256 2 (512)
I0630 12:08:34.537312 30262 net.cpp:156] Memory required for data: 339180544
I0630 12:08:34.537360 30262 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0630 12:08:34.538985 30262 net.cpp:91] Creating Layer ip2_ip2_0_split
I0630 12:08:34.539057 30262 net.cpp:425] ip2_ip2_0_split <- ip2
I0630 12:08:34.539255 30262 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0630 12:08:34.539315 30262 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0630 12:08:34.539428 30262 net.cpp:141] Setting up ip2_ip2_0_split
I0630 12:08:34.539485 30262 net.cpp:148] Top shape: 256 2 (512)
I0630 12:08:34.539541 30262 net.cpp:148] Top shape: 256 2 (512)
I0630 12:08:34.539588 30262 net.cpp:156] Memory required for data: 339184640
I0630 12:08:34.539636 30262 layer_factory.hpp:77] Creating layer accuracy
I0630 12:08:34.539697 30262 net.cpp:91] Creating Layer accuracy
I0630 12:08:34.539749 30262 net.cpp:425] accuracy <- ip2_ip2_0_split_0
I0630 12:08:34.539799 30262 net.cpp:425] accuracy <- label_testing_cells_1_split_0
I0630 12:08:34.539855 30262 net.cpp:399] accuracy -> accuracy
I0630 12:08:34.539921 30262 net.cpp:141] Setting up accuracy
I0630 12:08:34.539973 30262 net.cpp:148] Top shape: (1)
I0630 12:08:34.540017 30262 net.cpp:156] Memory required for data: 339184644
I0630 12:08:34.540068 30262 layer_factory.hpp:77] Creating layer loss
I0630 12:08:34.540120 30262 net.cpp:91] Creating Layer loss
I0630 12:08:34.540170 30262 net.cpp:425] loss <- ip2_ip2_0_split_1
I0630 12:08:34.540218 30262 net.cpp:425] loss <- label_testing_cells_1_split_1
I0630 12:08:34.540271 30262 net.cpp:399] loss -> loss
I0630 12:08:34.540328 30262 layer_factory.hpp:77] Creating layer loss
I0630 12:08:34.540514 30262 net.cpp:141] Setting up loss
I0630 12:08:34.540570 30262 net.cpp:148] Top shape: (1)
I0630 12:08:34.540621 30262 net.cpp:151]     with loss weight 1
I0630 12:08:34.540679 30262 net.cpp:156] Memory required for data: 339184648
I0630 12:08:34.540727 30262 net.cpp:217] loss needs backward computation.
I0630 12:08:34.540776 30262 net.cpp:219] accuracy does not need backward computation.
I0630 12:08:34.540827 30262 net.cpp:217] ip2_ip2_0_split needs backward computation.
I0630 12:08:34.540861 30262 net.cpp:217] ip2 needs backward computation.
I0630 12:08:34.540870 30262 net.cpp:217] relu1 needs backward computation.
I0630 12:08:34.540879 30262 net.cpp:217] ip1 needs backward computation.
I0630 12:08:34.540885 30262 net.cpp:217] pool2 needs backward computation.
I0630 12:08:34.540894 30262 net.cpp:217] conv2 needs backward computation.
I0630 12:08:34.540900 30262 net.cpp:217] pool1 needs backward computation.
I0630 12:08:34.540909 30262 net.cpp:217] conv1 needs backward computation.
I0630 12:08:34.540916 30262 net.cpp:219] label_testing_cells_1_split does not need backward computation.
I0630 12:08:34.540925 30262 net.cpp:219] testing_cells does not need backward computation.
I0630 12:08:34.540933 30262 net.cpp:261] This network produces output accuracy
I0630 12:08:34.540943 30262 net.cpp:261] This network produces output loss
I0630 12:08:34.540964 30262 net.cpp:274] Network initialization done.
I0630 12:08:34.541064 30262 solver.cpp:60] Solver scaffolding done.
I0630 12:08:34.541404 30262 caffe.cpp:219] Starting Optimization
I0630 12:08:34.541419 30262 solver.cpp:279] Solving fish_filter
I0630 12:08:34.541426 30262 solver.cpp:280] Learning Rate Policy: inv
I0630 12:08:34.546123 30262 solver.cpp:337] Iteration 0, Testing net (#0)
I0630 12:08:34.547924 30262 net.cpp:684] Ignoring source layer training_cells
I0630 12:08:34.558794 30262 net.cpp:684] Ignoring source layer drop1
I0630 12:08:54.201942 30262 solver.cpp:404]     Test net output #0: accuracy = 0.608203
I0630 12:08:54.201992 30262 solver.cpp:404]     Test net output #1: loss = 0.675401 (* 1 = 0.675401 loss)
I0630 12:08:56.968082 30262 solver.cpp:228] Iteration 0, loss = 0.919294
I0630 12:08:56.968130 30262 solver.cpp:244]     Train net output #0: loss = 0.919294 (* 1 = 0.919294 loss)
I0630 12:08:56.968147 30262 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0630 12:10:48.336526 30262 solver.cpp:228] Iteration 25, loss = 0.547531
I0630 12:10:48.336612 30262 solver.cpp:244]     Train net output #0: loss = 0.547531 (* 1 = 0.547531 loss)
I0630 12:10:48.336627 30262 sgd_solver.cpp:106] Iteration 25, lr = 0.000998129
I0630 12:12:29.397225 30262 solver.cpp:228] Iteration 50, loss = 0.593428
I0630 12:12:29.397331 30262 solver.cpp:244]     Train net output #0: loss = 0.593428 (* 1 = 0.593428 loss)
I0630 12:12:29.397346 30262 sgd_solver.cpp:106] Iteration 50, lr = 0.000996266
I0630 12:14:02.583781 30262 solver.cpp:228] Iteration 75, loss = 0.687746
I0630 12:14:02.583876 30262 solver.cpp:244]     Train net output #0: loss = 0.687746 (* 1 = 0.687746 loss)
I0630 12:14:02.583889 30262 sgd_solver.cpp:106] Iteration 75, lr = 0.000994412
I0630 12:15:29.997864 30262 solver.cpp:228] Iteration 100, loss = 0.654234
I0630 12:15:29.997954 30262 solver.cpp:244]     Train net output #0: loss = 0.654234 (* 1 = 0.654234 loss)
I0630 12:15:29.997968 30262 sgd_solver.cpp:106] Iteration 100, lr = 0.000992565
I0630 12:16:55.712074 30262 solver.cpp:228] Iteration 125, loss = 0.538491
I0630 12:16:55.712169 30262 solver.cpp:244]     Train net output #0: loss = 0.538491 (* 1 = 0.538491 loss)
I0630 12:16:55.712179 30262 sgd_solver.cpp:106] Iteration 125, lr = 0.000990726
I0630 12:18:20.444233 30262 solver.cpp:228] Iteration 150, loss = 0.428836
I0630 12:18:20.444324 30262 solver.cpp:244]     Train net output #0: loss = 0.428836 (* 1 = 0.428836 loss)
I0630 12:18:20.444335 30262 sgd_solver.cpp:106] Iteration 150, lr = 0.000988896
I0630 12:19:42.883175 30262 solver.cpp:228] Iteration 175, loss = 0.52143
I0630 12:19:42.883280 30262 solver.cpp:244]     Train net output #0: loss = 0.52143 (* 1 = 0.52143 loss)
I0630 12:19:42.883292 30262 sgd_solver.cpp:106] Iteration 175, lr = 0.000987073
I0630 12:21:04.803117 30262 solver.cpp:228] Iteration 200, loss = 0.583775
I0630 12:21:04.803206 30262 solver.cpp:244]     Train net output #0: loss = 0.583775 (* 1 = 0.583775 loss)
I0630 12:21:04.803225 30262 sgd_solver.cpp:106] Iteration 200, lr = 0.000985258
I0630 12:22:27.092208 30262 solver.cpp:228] Iteration 225, loss = 0.606943
I0630 12:22:27.092313 30262 solver.cpp:244]     Train net output #0: loss = 0.606943 (* 1 = 0.606943 loss)
I0630 12:22:27.092326 30262 sgd_solver.cpp:106] Iteration 225, lr = 0.000983451
I0630 12:23:47.452016 30262 solver.cpp:228] Iteration 250, loss = 0.505599
I0630 12:23:47.452112 30262 solver.cpp:244]     Train net output #0: loss = 0.505599 (* 1 = 0.505599 loss)
I0630 12:23:47.452126 30262 sgd_solver.cpp:106] Iteration 250, lr = 0.000981651
I0630 12:25:06.444936 30262 solver.cpp:228] Iteration 275, loss = 0.422297
I0630 12:25:06.445034 30262 solver.cpp:244]     Train net output #0: loss = 0.422297 (* 1 = 0.422297 loss)
I0630 12:25:06.445046 30262 sgd_solver.cpp:106] Iteration 275, lr = 0.000979859
I0630 12:26:24.883749 30262 solver.cpp:228] Iteration 300, loss = 0.50108
I0630 12:26:24.883846 30262 solver.cpp:244]     Train net output #0: loss = 0.50108 (* 1 = 0.50108 loss)
I0630 12:26:24.883859 30262 sgd_solver.cpp:106] Iteration 300, lr = 0.000978075
I0630 12:27:44.613312 30262 solver.cpp:228] Iteration 325, loss = 0.458521
I0630 12:27:44.613404 30262 solver.cpp:244]     Train net output #0: loss = 0.458521 (* 1 = 0.458521 loss)
I0630 12:27:44.613416 30262 sgd_solver.cpp:106] Iteration 325, lr = 0.000976298
I0630 12:29:03.924108 30262 solver.cpp:228] Iteration 350, loss = 0.504687
I0630 12:29:03.924201 30262 solver.cpp:244]     Train net output #0: loss = 0.504687 (* 1 = 0.504687 loss)
I0630 12:29:03.924216 30262 sgd_solver.cpp:106] Iteration 350, lr = 0.000974529
I0630 12:30:23.023437 30262 solver.cpp:228] Iteration 375, loss = 0.471816
I0630 12:30:23.023527 30262 solver.cpp:244]     Train net output #0: loss = 0.471816 (* 1 = 0.471816 loss)
I0630 12:30:23.023540 30262 sgd_solver.cpp:106] Iteration 375, lr = 0.000972767
I0630 12:31:42.547271 30262 solver.cpp:228] Iteration 400, loss = 0.292231
I0630 12:31:42.547374 30262 solver.cpp:244]     Train net output #0: loss = 0.292231 (* 1 = 0.292231 loss)
I0630 12:31:42.547389 30262 sgd_solver.cpp:106] Iteration 400, lr = 0.000971013
I0630 12:33:01.681114 30262 solver.cpp:228] Iteration 425, loss = 0.40408
I0630 12:33:01.681210 30262 solver.cpp:244]     Train net output #0: loss = 0.40408 (* 1 = 0.40408 loss)
I0630 12:33:01.681223 30262 sgd_solver.cpp:106] Iteration 425, lr = 0.000969266
I0630 12:34:19.955404 30262 solver.cpp:228] Iteration 450, loss = 0.41056
I0630 12:34:19.955513 30262 solver.cpp:244]     Train net output #0: loss = 0.41056 (* 1 = 0.41056 loss)
I0630 12:34:19.955531 30262 sgd_solver.cpp:106] Iteration 450, lr = 0.000967526
I0630 12:35:35.330406 30262 solver.cpp:228] Iteration 475, loss = 0.551225
I0630 12:35:35.330502 30262 solver.cpp:244]     Train net output #0: loss = 0.551225 (* 1 = 0.551225 loss)
I0630 12:35:35.330519 30262 sgd_solver.cpp:106] Iteration 475, lr = 0.000965794
I0630 12:36:50.220443 30262 solver.cpp:337] Iteration 500, Testing net (#0)
I0630 12:36:50.220525 30262 net.cpp:684] Ignoring source layer training_cells
I0630 12:36:50.220535 30262 net.cpp:684] Ignoring source layer drop1
I0630 12:37:02.773103 30262 solver.cpp:404]     Test net output #0: accuracy = 0.896094
I0630 12:37:02.773155 30262 solver.cpp:404]     Test net output #1: loss = 0.354872 (* 1 = 0.354872 loss)
I0630 12:37:04.583484 30262 solver.cpp:228] Iteration 500, loss = 0.504021
I0630 12:37:04.583540 30262 solver.cpp:244]     Train net output #0: loss = 0.504021 (* 1 = 0.504021 loss)
I0630 12:37:04.583550 30262 sgd_solver.cpp:106] Iteration 500, lr = 0.000964069
I0630 12:38:22.308795 30262 solver.cpp:228] Iteration 525, loss = 0.17961
I0630 12:38:22.308902 30262 solver.cpp:244]     Train net output #0: loss = 0.17961 (* 1 = 0.17961 loss)
I0630 12:38:22.308915 30262 sgd_solver.cpp:106] Iteration 525, lr = 0.000962351
I0630 12:39:39.940626 30262 solver.cpp:228] Iteration 550, loss = 0.340352
I0630 12:39:39.940735 30262 solver.cpp:244]     Train net output #0: loss = 0.340352 (* 1 = 0.340352 loss)
I0630 12:39:39.940749 30262 sgd_solver.cpp:106] Iteration 550, lr = 0.00096064
I0630 12:40:57.392608 30262 solver.cpp:228] Iteration 575, loss = 0.446207
I0630 12:40:57.392707 30262 solver.cpp:244]     Train net output #0: loss = 0.446207 (* 1 = 0.446207 loss)
I0630 12:40:57.392719 30262 sgd_solver.cpp:106] Iteration 575, lr = 0.000958936
I0630 12:42:15.056977 30262 solver.cpp:228] Iteration 600, loss = 0.540511
I0630 12:42:15.057077 30262 solver.cpp:244]     Train net output #0: loss = 0.54051 (* 1 = 0.54051 loss)
I0630 12:42:15.057090 30262 sgd_solver.cpp:106] Iteration 600, lr = 0.00095724
I0630 12:43:32.643273 30262 solver.cpp:228] Iteration 625, loss = 0.307748
I0630 12:43:32.643367 30262 solver.cpp:244]     Train net output #0: loss = 0.307748 (* 1 = 0.307748 loss)
I0630 12:43:32.643378 30262 sgd_solver.cpp:106] Iteration 625, lr = 0.00095555
I0630 12:44:50.440011 30262 solver.cpp:228] Iteration 650, loss = 0.216354
I0630 12:44:50.440104 30262 solver.cpp:244]     Train net output #0: loss = 0.216354 (* 1 = 0.216354 loss)
I0630 12:44:50.440117 30262 sgd_solver.cpp:106] Iteration 650, lr = 0.000953867
I0630 12:46:09.067860 30262 solver.cpp:228] Iteration 675, loss = 0.758957
I0630 12:46:09.067963 30262 solver.cpp:244]     Train net output #0: loss = 0.758957 (* 1 = 0.758957 loss)
I0630 12:46:09.067981 30262 sgd_solver.cpp:106] Iteration 675, lr = 0.000952191
I0630 12:47:26.557363 30262 solver.cpp:228] Iteration 700, loss = 0.375156
I0630 12:47:26.557459 30262 solver.cpp:244]     Train net output #0: loss = 0.375156 (* 1 = 0.375156 loss)
I0630 12:47:26.557473 30262 sgd_solver.cpp:106] Iteration 700, lr = 0.000950522
I0630 12:48:44.173519 30262 solver.cpp:228] Iteration 725, loss = 0.345877
I0630 12:48:44.173611 30262 solver.cpp:244]     Train net output #0: loss = 0.345877 (* 1 = 0.345877 loss)
I0630 12:48:44.173624 30262 sgd_solver.cpp:106] Iteration 725, lr = 0.00094886
I0630 12:50:02.202639 30262 solver.cpp:228] Iteration 750, loss = 0.249714
I0630 12:50:02.202733 30262 solver.cpp:244]     Train net output #0: loss = 0.249714 (* 1 = 0.249714 loss)
I0630 12:50:02.202745 30262 sgd_solver.cpp:106] Iteration 750, lr = 0.000947204
I0630 12:51:19.714689 30262 solver.cpp:228] Iteration 775, loss = 0.260149
I0630 12:51:19.714795 30262 solver.cpp:244]     Train net output #0: loss = 0.260149 (* 1 = 0.260149 loss)
I0630 12:51:19.714808 30262 sgd_solver.cpp:106] Iteration 775, lr = 0.000945556
I0630 12:52:36.831887 30262 solver.cpp:228] Iteration 800, loss = 0.425923
I0630 12:52:36.831993 30262 solver.cpp:244]     Train net output #0: loss = 0.425923 (* 1 = 0.425923 loss)
I0630 12:52:36.832010 30262 sgd_solver.cpp:106] Iteration 800, lr = 0.000943913
I0630 12:53:53.947587 30262 solver.cpp:228] Iteration 825, loss = 0.300259
I0630 12:53:53.947692 30262 solver.cpp:244]     Train net output #0: loss = 0.300259 (* 1 = 0.300259 loss)
I0630 12:53:53.947705 30262 sgd_solver.cpp:106] Iteration 825, lr = 0.000942278
I0630 12:55:11.124814 30262 solver.cpp:228] Iteration 850, loss = 0.364978
I0630 12:55:11.124918 30262 solver.cpp:244]     Train net output #0: loss = 0.364978 (* 1 = 0.364978 loss)
I0630 12:55:11.124938 30262 sgd_solver.cpp:106] Iteration 850, lr = 0.000940649
I0630 12:56:27.259507 30262 solver.cpp:228] Iteration 875, loss = 0.224699
I0630 12:56:27.259611 30262 solver.cpp:244]     Train net output #0: loss = 0.224699 (* 1 = 0.224699 loss)
I0630 12:56:27.259624 30262 sgd_solver.cpp:106] Iteration 875, lr = 0.000939027
I0630 12:57:43.978163 30262 solver.cpp:228] Iteration 900, loss = 0.186526
I0630 12:57:43.978255 30262 solver.cpp:244]     Train net output #0: loss = 0.186526 (* 1 = 0.186526 loss)
I0630 12:57:43.978269 30262 sgd_solver.cpp:106] Iteration 900, lr = 0.000937411
I0630 12:59:00.274453 30262 solver.cpp:228] Iteration 925, loss = 0.353872
I0630 12:59:00.274559 30262 solver.cpp:244]     Train net output #0: loss = 0.353872 (* 1 = 0.353872 loss)
I0630 12:59:00.274574 30262 sgd_solver.cpp:106] Iteration 925, lr = 0.000935802
I0630 13:00:16.669435 30262 solver.cpp:228] Iteration 950, loss = 0.388498
I0630 13:00:16.669528 30262 solver.cpp:244]     Train net output #0: loss = 0.388498 (* 1 = 0.388498 loss)
I0630 13:00:16.669540 30262 sgd_solver.cpp:106] Iteration 950, lr = 0.000934199
I0630 13:01:31.285549 30262 solver.cpp:228] Iteration 975, loss = 0.324958
I0630 13:01:31.285655 30262 solver.cpp:244]     Train net output #0: loss = 0.324958 (* 1 = 0.324958 loss)
I0630 13:01:31.285666 30262 sgd_solver.cpp:106] Iteration 975, lr = 0.000932603
I0630 13:02:45.728664 30262 solver.cpp:454] Snapshotting to binary proto file fish_net_pretrain_output_iter_1000.caffemodel
I0630 13:02:47.373064 30262 sgd_solver.cpp:273] Snapshotting solver state to binary proto file fish_net_pretrain_output_iter_1000.solverstate
I0630 13:02:47.373409 30262 solver.cpp:337] Iteration 1000, Testing net (#0)
I0630 13:02:47.373421 30262 net.cpp:684] Ignoring source layer training_cells
I0630 13:02:47.373430 30262 net.cpp:684] Ignoring source layer drop1
I0630 13:02:58.681519 30262 solver.cpp:404]     Test net output #0: accuracy = 0.911328
I0630 13:02:58.681556 30262 solver.cpp:404]     Test net output #1: loss = 0.260052 (* 1 = 0.260052 loss)
I0630 13:03:00.420151 30262 solver.cpp:228] Iteration 1000, loss = 0.343705
I0630 13:03:00.420191 30262 solver.cpp:244]     Train net output #0: loss = 0.343705 (* 1 = 0.343705 loss)
I0630 13:03:00.420200 30262 sgd_solver.cpp:106] Iteration 1000, lr = 0.000931013
I0630 13:04:17.637449 30262 solver.cpp:228] Iteration 1025, loss = 0.297333
I0630 13:04:17.637547 30262 solver.cpp:244]     Train net output #0: loss = 0.297333 (* 1 = 0.297333 loss)
I0630 13:04:17.637563 30262 sgd_solver.cpp:106] Iteration 1025, lr = 0.000929429
I0630 13:05:36.861209 30262 solver.cpp:228] Iteration 1050, loss = 0.265879
I0630 13:05:36.861343 30262 solver.cpp:244]     Train net output #0: loss = 0.265879 (* 1 = 0.265879 loss)
I0630 13:05:36.861358 30262 sgd_solver.cpp:106] Iteration 1050, lr = 0.000927851
I0630 13:06:55.175674 30262 solver.cpp:228] Iteration 1075, loss = 0.315802
I0630 13:06:55.175772 30262 solver.cpp:244]     Train net output #0: loss = 0.315802 (* 1 = 0.315802 loss)
I0630 13:06:55.175787 30262 sgd_solver.cpp:106] Iteration 1075, lr = 0.00092628
I0630 13:08:13.386013 30262 solver.cpp:228] Iteration 1100, loss = 0.513449
I0630 13:08:13.386128 30262 solver.cpp:244]     Train net output #0: loss = 0.513449 (* 1 = 0.513449 loss)
I0630 13:08:13.386142 30262 sgd_solver.cpp:106] Iteration 1100, lr = 0.000924715
I0630 13:09:29.649845 30262 solver.cpp:228] Iteration 1125, loss = 0.265803
I0630 13:09:29.649958 30262 solver.cpp:244]     Train net output #0: loss = 0.265803 (* 1 = 0.265803 loss)
I0630 13:09:29.649973 30262 sgd_solver.cpp:106] Iteration 1125, lr = 0.000923156
I0630 13:10:47.378304 30262 solver.cpp:228] Iteration 1150, loss = 0.351178
I0630 13:10:47.378408 30262 solver.cpp:244]     Train net output #0: loss = 0.351179 (* 1 = 0.351179 loss)
I0630 13:10:47.378423 30262 sgd_solver.cpp:106] Iteration 1150, lr = 0.000921603
I0630 13:12:06.537075 30262 solver.cpp:228] Iteration 1175, loss = 0.297617
I0630 13:12:06.537173 30262 solver.cpp:244]     Train net output #0: loss = 0.297617 (* 1 = 0.297617 loss)
I0630 13:12:06.537187 30262 sgd_solver.cpp:106] Iteration 1175, lr = 0.000920056
I0630 13:13:26.563591 30262 solver.cpp:228] Iteration 1200, loss = 0.254686
I0630 13:13:26.563690 30262 solver.cpp:244]     Train net output #0: loss = 0.254686 (* 1 = 0.254686 loss)
I0630 13:13:26.563704 30262 sgd_solver.cpp:106] Iteration 1200, lr = 0.000918516
I0630 13:14:44.484596 30262 solver.cpp:228] Iteration 1225, loss = 0.165162
I0630 13:14:44.484691 30262 solver.cpp:244]     Train net output #0: loss = 0.165162 (* 1 = 0.165162 loss)
I0630 13:14:44.484705 30262 sgd_solver.cpp:106] Iteration 1225, lr = 0.000916981
I0630 13:16:02.373245 30262 solver.cpp:228] Iteration 1250, loss = 0.32822
I0630 13:16:02.373353 30262 solver.cpp:244]     Train net output #0: loss = 0.32822 (* 1 = 0.32822 loss)
I0630 13:16:02.373368 30262 sgd_solver.cpp:106] Iteration 1250, lr = 0.000915452
I0630 13:17:20.578608 30262 solver.cpp:228] Iteration 1275, loss = 0.574905
I0630 13:17:20.578701 30262 solver.cpp:244]     Train net output #0: loss = 0.574905 (* 1 = 0.574905 loss)
I0630 13:17:20.578713 30262 sgd_solver.cpp:106] Iteration 1275, lr = 0.000913929
I0630 13:18:37.785590 30262 solver.cpp:228] Iteration 1300, loss = 0.52992
I0630 13:18:37.785686 30262 solver.cpp:244]     Train net output #0: loss = 0.52992 (* 1 = 0.52992 loss)
I0630 13:18:37.785697 30262 sgd_solver.cpp:106] Iteration 1300, lr = 0.000912412
I0630 13:19:54.509904 30262 solver.cpp:228] Iteration 1325, loss = 0.291544
I0630 13:19:54.509987 30262 solver.cpp:244]     Train net output #0: loss = 0.291544 (* 1 = 0.291544 loss)
I0630 13:19:54.509999 30262 sgd_solver.cpp:106] Iteration 1325, lr = 0.000910901
I0630 13:21:11.591819 30262 solver.cpp:228] Iteration 1350, loss = 0.205009
I0630 13:21:11.591924 30262 solver.cpp:244]     Train net output #0: loss = 0.205009 (* 1 = 0.205009 loss)
I0630 13:21:11.591938 30262 sgd_solver.cpp:106] Iteration 1350, lr = 0.000909396
I0630 13:22:29.643612 30262 solver.cpp:228] Iteration 1375, loss = 0.280899
I0630 13:22:29.643723 30262 solver.cpp:244]     Train net output #0: loss = 0.280899 (* 1 = 0.280899 loss)
I0630 13:22:29.643736 30262 sgd_solver.cpp:106] Iteration 1375, lr = 0.000907897
I0630 13:23:49.392186 30262 solver.cpp:228] Iteration 1400, loss = 0.699463
I0630 13:23:49.392274 30262 solver.cpp:244]     Train net output #0: loss = 0.699463 (* 1 = 0.699463 loss)
I0630 13:23:49.392290 30262 sgd_solver.cpp:106] Iteration 1400, lr = 0.000906403
I0630 13:25:08.933992 30262 solver.cpp:228] Iteration 1425, loss = 0.350913
I0630 13:25:08.934120 30262 solver.cpp:244]     Train net output #0: loss = 0.350913 (* 1 = 0.350913 loss)
I0630 13:25:08.934139 30262 sgd_solver.cpp:106] Iteration 1425, lr = 0.000904915
I0630 13:26:28.388069 30262 solver.cpp:228] Iteration 1450, loss = 0.30742
I0630 13:26:28.388167 30262 solver.cpp:244]     Train net output #0: loss = 0.30742 (* 1 = 0.30742 loss)
I0630 13:26:28.388185 30262 sgd_solver.cpp:106] Iteration 1450, lr = 0.000903433
I0630 13:27:45.542642 30262 solver.cpp:228] Iteration 1475, loss = 0.238495
I0630 13:27:45.542738 30262 solver.cpp:244]     Train net output #0: loss = 0.238496 (* 1 = 0.238496 loss)
I0630 13:27:45.542763 30262 sgd_solver.cpp:106] Iteration 1475, lr = 0.000901956
I0630 13:29:01.095609 30262 solver.cpp:337] Iteration 1500, Testing net (#0)
I0630 13:29:01.095711 30262 net.cpp:684] Ignoring source layer training_cells
I0630 13:29:01.095721 30262 net.cpp:684] Ignoring source layer drop1
I0630 13:29:14.243844 30262 solver.cpp:404]     Test net output #0: accuracy = 0.941016
I0630 13:29:14.243894 30262 solver.cpp:404]     Test net output #1: loss = 0.209021 (* 1 = 0.209021 loss)
I0630 13:29:15.661298 30262 solver.cpp:228] Iteration 1500, loss = 0.19882
I0630 13:29:15.661351 30262 solver.cpp:244]     Train net output #0: loss = 0.19882 (* 1 = 0.19882 loss)
I0630 13:29:15.661363 30262 sgd_solver.cpp:106] Iteration 1500, lr = 0.000900485
I0630 13:30:34.136788 30262 solver.cpp:228] Iteration 1525, loss = 0.16246
I0630 13:30:34.136885 30262 solver.cpp:244]     Train net output #0: loss = 0.16246 (* 1 = 0.16246 loss)
I0630 13:30:34.136900 30262 sgd_solver.cpp:106] Iteration 1525, lr = 0.00089902
I0630 13:31:52.235297 30262 solver.cpp:228] Iteration 1550, loss = 0.544514
I0630 13:31:52.235400 30262 solver.cpp:244]     Train net output #0: loss = 0.544514 (* 1 = 0.544514 loss)
I0630 13:31:52.235414 30262 sgd_solver.cpp:106] Iteration 1550, lr = 0.00089756
I0630 13:33:10.938360 30262 solver.cpp:228] Iteration 1575, loss = 0.298013
I0630 13:33:10.938468 30262 solver.cpp:244]     Train net output #0: loss = 0.298013 (* 1 = 0.298013 loss)
I0630 13:33:10.938489 30262 sgd_solver.cpp:106] Iteration 1575, lr = 0.000896106
I0630 13:34:32.413700 30262 solver.cpp:228] Iteration 1600, loss = 0.238084
I0630 13:34:32.413806 30262 solver.cpp:244]     Train net output #0: loss = 0.238084 (* 1 = 0.238084 loss)
I0630 13:34:32.413818 30262 sgd_solver.cpp:106] Iteration 1600, lr = 0.000894657
I0630 13:35:52.635356 30262 solver.cpp:228] Iteration 1625, loss = 0.21518
I0630 13:35:52.635440 30262 solver.cpp:244]     Train net output #0: loss = 0.21518 (* 1 = 0.21518 loss)
I0630 13:35:52.635454 30262 sgd_solver.cpp:106] Iteration 1625, lr = 0.000893214
I0630 13:37:11.502955 30262 solver.cpp:228] Iteration 1650, loss = 0.143657
I0630 13:37:11.503056 30262 solver.cpp:244]     Train net output #0: loss = 0.143657 (* 1 = 0.143657 loss)
I0630 13:37:11.503069 30262 sgd_solver.cpp:106] Iteration 1650, lr = 0.000891776
I0630 13:38:32.524447 30262 solver.cpp:228] Iteration 1675, loss = 0.345957
I0630 13:38:32.524539 30262 solver.cpp:244]     Train net output #0: loss = 0.345958 (* 1 = 0.345958 loss)
I0630 13:38:32.524552 30262 sgd_solver.cpp:106] Iteration 1675, lr = 0.000890343
I0630 13:39:51.452903 30262 solver.cpp:228] Iteration 1700, loss = 0.265336
I0630 13:39:51.452999 30262 solver.cpp:244]     Train net output #0: loss = 0.265336 (* 1 = 0.265336 loss)
I0630 13:39:51.453013 30262 sgd_solver.cpp:106] Iteration 1700, lr = 0.000888916
I0630 13:41:10.913103 30262 solver.cpp:228] Iteration 1725, loss = 0.379853
I0630 13:41:10.913209 30262 solver.cpp:244]     Train net output #0: loss = 0.379853 (* 1 = 0.379853 loss)
I0630 13:41:10.913225 30262 sgd_solver.cpp:106] Iteration 1725, lr = 0.000887494
I0630 13:42:30.436594 30262 solver.cpp:228] Iteration 1750, loss = 0.220518
I0630 13:42:30.436691 30262 solver.cpp:244]     Train net output #0: loss = 0.220518 (* 1 = 0.220518 loss)
I0630 13:42:30.436703 30262 sgd_solver.cpp:106] Iteration 1750, lr = 0.000886077
I0630 13:43:50.988188 30262 solver.cpp:228] Iteration 1775, loss = 0.170607
I0630 13:43:50.988291 30262 solver.cpp:244]     Train net output #0: loss = 0.170607 (* 1 = 0.170607 loss)
I0630 13:43:50.988304 30262 sgd_solver.cpp:106] Iteration 1775, lr = 0.000884666
I0630 13:45:12.107278 30262 solver.cpp:228] Iteration 1800, loss = 0.439636
I0630 13:45:12.107381 30262 solver.cpp:244]     Train net output #0: loss = 0.439636 (* 1 = 0.439636 loss)
I0630 13:45:12.107398 30262 sgd_solver.cpp:106] Iteration 1800, lr = 0.00088326
I0630 13:46:30.777431 30262 solver.cpp:228] Iteration 1825, loss = 0.183682
I0630 13:46:30.777524 30262 solver.cpp:244]     Train net output #0: loss = 0.183682 (* 1 = 0.183682 loss)
I0630 13:46:30.777535 30262 sgd_solver.cpp:106] Iteration 1825, lr = 0.000881859
I0630 13:47:50.102833 30262 solver.cpp:228] Iteration 1850, loss = 0.133814
I0630 13:47:50.102948 30262 solver.cpp:244]     Train net output #0: loss = 0.133814 (* 1 = 0.133814 loss)
I0630 13:47:50.102960 30262 sgd_solver.cpp:106] Iteration 1850, lr = 0.000880463
I0630 13:49:09.750636 30262 solver.cpp:228] Iteration 1875, loss = 0.378823
I0630 13:49:09.750727 30262 solver.cpp:244]     Train net output #0: loss = 0.378823 (* 1 = 0.378823 loss)
I0630 13:49:09.750738 30262 sgd_solver.cpp:106] Iteration 1875, lr = 0.000879073
I0630 13:50:29.257912 30262 solver.cpp:228] Iteration 1900, loss = 0.181639
I0630 13:50:29.258016 30262 solver.cpp:244]     Train net output #0: loss = 0.181639 (* 1 = 0.181639 loss)
I0630 13:50:29.258031 30262 sgd_solver.cpp:106] Iteration 1900, lr = 0.000877687
I0630 13:51:49.197376 30262 solver.cpp:228] Iteration 1925, loss = 0.214233
I0630 13:51:49.197474 30262 solver.cpp:244]     Train net output #0: loss = 0.214233 (* 1 = 0.214233 loss)
I0630 13:51:49.197487 30262 sgd_solver.cpp:106] Iteration 1925, lr = 0.000876307
I0630 13:53:08.264883 30262 solver.cpp:228] Iteration 1950, loss = 0.263037
I0630 13:53:08.265023 30262 solver.cpp:244]     Train net output #0: loss = 0.263037 (* 1 = 0.263037 loss)
I0630 13:53:08.265045 30262 sgd_solver.cpp:106] Iteration 1950, lr = 0.000874932
I0630 13:54:25.190115 30262 solver.cpp:228] Iteration 1975, loss = 0.294784
I0630 13:54:25.190222 30262 solver.cpp:244]     Train net output #0: loss = 0.294784 (* 1 = 0.294784 loss)
I0630 13:54:25.190237 30262 sgd_solver.cpp:106] Iteration 1975, lr = 0.000873561
I0630 13:55:39.906060 30262 solver.cpp:454] Snapshotting to binary proto file fish_net_pretrain_output_iter_2000.caffemodel
I0630 13:55:41.554533 30262 sgd_solver.cpp:273] Snapshotting solver state to binary proto file fish_net_pretrain_output_iter_2000.solverstate
I0630 13:55:41.554962 30262 solver.cpp:337] Iteration 2000, Testing net (#0)
I0630 13:55:41.554980 30262 net.cpp:684] Ignoring source layer training_cells
I0630 13:55:41.554988 30262 net.cpp:684] Ignoring source layer drop1
I0630 13:55:53.129601 30262 solver.cpp:404]     Test net output #0: accuracy = 0.939453
I0630 13:55:53.129653 30262 solver.cpp:404]     Test net output #1: loss = 0.181739 (* 1 = 0.181739 loss)
I0630 13:55:55.019067 30262 solver.cpp:228] Iteration 2000, loss = 0.124635
I0630 13:55:55.019117 30262 solver.cpp:244]     Train net output #0: loss = 0.124635 (* 1 = 0.124635 loss)
I0630 13:55:55.019129 30262 sgd_solver.cpp:106] Iteration 2000, lr = 0.000872196
I0630 13:57:13.308748 30262 solver.cpp:228] Iteration 2025, loss = 0.221816
I0630 13:57:13.308845 30262 solver.cpp:244]     Train net output #0: loss = 0.221816 (* 1 = 0.221816 loss)
I0630 13:57:13.308857 30262 sgd_solver.cpp:106] Iteration 2025, lr = 0.000870836
I0630 13:58:32.300475 30262 solver.cpp:228] Iteration 2050, loss = 0.337908
I0630 13:58:32.300571 30262 solver.cpp:244]     Train net output #0: loss = 0.337909 (* 1 = 0.337909 loss)
I0630 13:58:32.300586 30262 sgd_solver.cpp:106] Iteration 2050, lr = 0.00086948
I0630 13:59:53.145553 30262 solver.cpp:228] Iteration 2075, loss = 0.247533
I0630 13:59:53.145653 30262 solver.cpp:244]     Train net output #0: loss = 0.247533 (* 1 = 0.247533 loss)
I0630 13:59:53.145665 30262 sgd_solver.cpp:106] Iteration 2075, lr = 0.00086813
I0630 14:01:13.275316 30262 solver.cpp:228] Iteration 2100, loss = 0.309906
I0630 14:01:13.275425 30262 solver.cpp:244]     Train net output #0: loss = 0.309906 (* 1 = 0.309906 loss)
I0630 14:01:13.275439 30262 sgd_solver.cpp:106] Iteration 2100, lr = 0.000866784
I0630 14:02:31.431241 30262 solver.cpp:228] Iteration 2125, loss = 0.0873579
I0630 14:02:31.431350 30262 solver.cpp:244]     Train net output #0: loss = 0.087358 (* 1 = 0.087358 loss)
I0630 14:02:31.431365 30262 sgd_solver.cpp:106] Iteration 2125, lr = 0.000865443
I0630 14:03:51.776617 30262 solver.cpp:228] Iteration 2150, loss = 0.161807
I0630 14:03:51.776713 30262 solver.cpp:244]     Train net output #0: loss = 0.161808 (* 1 = 0.161808 loss)
I0630 14:03:51.776724 30262 sgd_solver.cpp:106] Iteration 2150, lr = 0.000864108
I0630 14:05:12.394330 30262 solver.cpp:228] Iteration 2175, loss = 0.180722
I0630 14:05:12.394439 30262 solver.cpp:244]     Train net output #0: loss = 0.180722 (* 1 = 0.180722 loss)
I0630 14:05:12.394451 30262 sgd_solver.cpp:106] Iteration 2175, lr = 0.000862776
I0630 14:06:30.976900 30262 solver.cpp:228] Iteration 2200, loss = 0.233461
I0630 14:06:30.977000 30262 solver.cpp:244]     Train net output #0: loss = 0.233461 (* 1 = 0.233461 loss)
I0630 14:06:30.977020 30262 sgd_solver.cpp:106] Iteration 2200, lr = 0.00086145
I0630 14:07:51.311565 30262 solver.cpp:228] Iteration 2225, loss = 0.236999
I0630 14:07:51.311660 30262 solver.cpp:244]     Train net output #0: loss = 0.236999 (* 1 = 0.236999 loss)
I0630 14:07:51.311674 30262 sgd_solver.cpp:106] Iteration 2225, lr = 0.000860129
I0630 14:09:13.710599 30262 solver.cpp:228] Iteration 2250, loss = 0.485967
I0630 14:09:13.710708 30262 solver.cpp:244]     Train net output #0: loss = 0.485967 (* 1 = 0.485967 loss)
I0630 14:09:13.710726 30262 sgd_solver.cpp:106] Iteration 2250, lr = 0.000858812
I0630 14:10:34.560056 30262 solver.cpp:228] Iteration 2275, loss = 0.229567
I0630 14:10:34.560143 30262 solver.cpp:244]     Train net output #0: loss = 0.229567 (* 1 = 0.229567 loss)
I0630 14:10:34.560158 30262 sgd_solver.cpp:106] Iteration 2275, lr = 0.0008575
I0630 14:11:54.993234 30262 solver.cpp:228] Iteration 2300, loss = 0.199367
I0630 14:11:54.993340 30262 solver.cpp:244]     Train net output #0: loss = 0.199367 (* 1 = 0.199367 loss)
I0630 14:11:54.993351 30262 sgd_solver.cpp:106] Iteration 2300, lr = 0.000856192
I0630 14:13:15.557291 30262 solver.cpp:228] Iteration 2325, loss = 0.185469
I0630 14:13:15.557390 30262 solver.cpp:244]     Train net output #0: loss = 0.18547 (* 1 = 0.18547 loss)
I0630 14:13:15.557402 30262 sgd_solver.cpp:106] Iteration 2325, lr = 0.000854889
I0630 14:14:37.224015 30262 solver.cpp:228] Iteration 2350, loss = 0.111851
I0630 14:14:37.224123 30262 solver.cpp:244]     Train net output #0: loss = 0.111851 (* 1 = 0.111851 loss)
I0630 14:14:37.224136 30262 sgd_solver.cpp:106] Iteration 2350, lr = 0.000853591
I0630 14:16:00.133863 30262 solver.cpp:228] Iteration 2375, loss = 0.486013
I0630 14:16:00.133960 30262 solver.cpp:244]     Train net output #0: loss = 0.486013 (* 1 = 0.486013 loss)
I0630 14:16:00.133972 30262 sgd_solver.cpp:106] Iteration 2375, lr = 0.000852297
I0630 14:17:21.087405 30262 solver.cpp:228] Iteration 2400, loss = 0.12435
I0630 14:17:21.087513 30262 solver.cpp:244]     Train net output #0: loss = 0.12435 (* 1 = 0.12435 loss)
I0630 14:17:21.087532 30262 sgd_solver.cpp:106] Iteration 2400, lr = 0.000851008
I0630 14:18:43.535786 30262 solver.cpp:228] Iteration 2425, loss = 0.135766
I0630 14:18:43.535871 30262 solver.cpp:244]     Train net output #0: loss = 0.135766 (* 1 = 0.135766 loss)
I0630 14:18:43.535883 30262 sgd_solver.cpp:106] Iteration 2425, lr = 0.000849724
I0630 14:20:04.075606 30262 solver.cpp:228] Iteration 2450, loss = 0.145185
I0630 14:20:04.075708 30262 solver.cpp:244]     Train net output #0: loss = 0.145185 (* 1 = 0.145185 loss)
I0630 14:20:04.075721 30262 sgd_solver.cpp:106] Iteration 2450, lr = 0.000848444
I0630 14:21:24.485580 30262 solver.cpp:228] Iteration 2475, loss = 0.223812
I0630 14:21:24.485673 30262 solver.cpp:244]     Train net output #0: loss = 0.223812 (* 1 = 0.223812 loss)
I0630 14:21:24.485688 30262 sgd_solver.cpp:106] Iteration 2475, lr = 0.000847168
I0630 14:22:38.636972 30262 solver.cpp:337] Iteration 2500, Testing net (#0)
I0630 14:22:38.637053 30262 net.cpp:684] Ignoring source layer training_cells
I0630 14:22:38.637061 30262 net.cpp:684] Ignoring source layer drop1
I0630 14:22:51.891793 30262 solver.cpp:404]     Test net output #0: accuracy = 0.946094
I0630 14:22:51.891845 30262 solver.cpp:404]     Test net output #1: loss = 0.176675 (* 1 = 0.176675 loss)
I0630 14:22:53.318291 30262 solver.cpp:228] Iteration 2500, loss = 0.368397
I0630 14:22:53.318341 30262 solver.cpp:244]     Train net output #0: loss = 0.368397 (* 1 = 0.368397 loss)
I0630 14:22:53.318352 30262 sgd_solver.cpp:106] Iteration 2500, lr = 0.000845897
I0630 14:24:13.232920 30262 solver.cpp:228] Iteration 2525, loss = 0.151669
I0630 14:24:13.233032 30262 solver.cpp:244]     Train net output #0: loss = 0.151669 (* 1 = 0.151669 loss)
I0630 14:24:13.233048 30262 sgd_solver.cpp:106] Iteration 2525, lr = 0.00084463
I0630 14:25:32.350529 30262 solver.cpp:228] Iteration 2550, loss = 0.104014
I0630 14:25:32.350633 30262 solver.cpp:244]     Train net output #0: loss = 0.104014 (* 1 = 0.104014 loss)
I0630 14:25:32.350648 30262 sgd_solver.cpp:106] Iteration 2550, lr = 0.000843368
I0630 14:26:52.827477 30262 solver.cpp:228] Iteration 2575, loss = 0.18154
I0630 14:26:52.827571 30262 solver.cpp:244]     Train net output #0: loss = 0.18154 (* 1 = 0.18154 loss)
I0630 14:26:52.827586 30262 sgd_solver.cpp:106] Iteration 2575, lr = 0.00084211
I0630 14:28:11.756765 30262 solver.cpp:228] Iteration 2600, loss = 0.402248
I0630 14:28:11.756880 30262 solver.cpp:244]     Train net output #0: loss = 0.402248 (* 1 = 0.402248 loss)
I0630 14:28:11.756893 30262 sgd_solver.cpp:106] Iteration 2600, lr = 0.000840857
I0630 14:29:32.059145 30262 solver.cpp:228] Iteration 2625, loss = 0.355395
I0630 14:29:32.059236 30262 solver.cpp:244]     Train net output #0: loss = 0.355395 (* 1 = 0.355395 loss)
I0630 14:29:32.059247 30262 sgd_solver.cpp:106] Iteration 2625, lr = 0.000839608
I0630 14:30:51.909270 30262 solver.cpp:228] Iteration 2650, loss = 0.407095
I0630 14:30:51.909379 30262 solver.cpp:244]     Train net output #0: loss = 0.407096 (* 1 = 0.407096 loss)
I0630 14:30:51.909394 30262 sgd_solver.cpp:106] Iteration 2650, lr = 0.000838363
I0630 14:32:10.291939 30262 solver.cpp:228] Iteration 2675, loss = 0.158346
I0630 14:32:10.292034 30262 solver.cpp:244]     Train net output #0: loss = 0.158346 (* 1 = 0.158346 loss)
I0630 14:32:10.292050 30262 sgd_solver.cpp:106] Iteration 2675, lr = 0.000837123
I0630 14:33:28.379477 30262 solver.cpp:228] Iteration 2700, loss = 0.153947
I0630 14:33:28.379576 30262 solver.cpp:244]     Train net output #0: loss = 0.153947 (* 1 = 0.153947 loss)
I0630 14:33:28.379587 30262 sgd_solver.cpp:106] Iteration 2700, lr = 0.000835886
I0630 14:34:46.847224 30262 solver.cpp:228] Iteration 2725, loss = 0.281508
I0630 14:34:46.847331 30262 solver.cpp:244]     Train net output #0: loss = 0.281509 (* 1 = 0.281509 loss)
I0630 14:34:46.847343 30262 sgd_solver.cpp:106] Iteration 2725, lr = 0.000834654
I0630 14:36:04.463515 30262 solver.cpp:228] Iteration 2750, loss = 0.298036
I0630 14:36:04.463608 30262 solver.cpp:244]     Train net output #0: loss = 0.298036 (* 1 = 0.298036 loss)
I0630 14:36:04.463624 30262 sgd_solver.cpp:106] Iteration 2750, lr = 0.000833427
I0630 14:37:23.153883 30262 solver.cpp:228] Iteration 2775, loss = 0.264159
I0630 14:37:23.153980 30262 solver.cpp:244]     Train net output #0: loss = 0.264159 (* 1 = 0.264159 loss)
I0630 14:37:23.153993 30262 sgd_solver.cpp:106] Iteration 2775, lr = 0.000832203
I0630 14:38:42.493327 30262 solver.cpp:228] Iteration 2800, loss = 0.116726
I0630 14:38:42.493417 30262 solver.cpp:244]     Train net output #0: loss = 0.116727 (* 1 = 0.116727 loss)
I0630 14:38:42.493430 30262 sgd_solver.cpp:106] Iteration 2800, lr = 0.000830984
I0630 14:40:01.629055 30262 solver.cpp:228] Iteration 2825, loss = 0.220953
I0630 14:40:01.629151 30262 solver.cpp:244]     Train net output #0: loss = 0.220953 (* 1 = 0.220953 loss)
I0630 14:40:01.629164 30262 sgd_solver.cpp:106] Iteration 2825, lr = 0.000829769
I0630 14:41:22.148613 30262 solver.cpp:228] Iteration 2850, loss = 0.112111
I0630 14:41:22.148717 30262 solver.cpp:244]     Train net output #0: loss = 0.112111 (* 1 = 0.112111 loss)
I0630 14:41:22.148731 30262 sgd_solver.cpp:106] Iteration 2850, lr = 0.000828558
I0630 14:42:41.802851 30262 solver.cpp:228] Iteration 2875, loss = 0.242728
I0630 14:42:41.802947 30262 solver.cpp:244]     Train net output #0: loss = 0.242728 (* 1 = 0.242728 loss)
I0630 14:42:41.802961 30262 sgd_solver.cpp:106] Iteration 2875, lr = 0.000827351
I0630 14:44:03.037197 30262 solver.cpp:228] Iteration 2900, loss = 0.195887
I0630 14:44:03.037302 30262 solver.cpp:244]     Train net output #0: loss = 0.195887 (* 1 = 0.195887 loss)
I0630 14:44:03.037313 30262 sgd_solver.cpp:106] Iteration 2900, lr = 0.000826148
I0630 14:45:22.426944 30262 solver.cpp:228] Iteration 2925, loss = 0.388782
I0630 14:45:22.427045 30262 solver.cpp:244]     Train net output #0: loss = 0.388782 (* 1 = 0.388782 loss)
I0630 14:45:22.427063 30262 sgd_solver.cpp:106] Iteration 2925, lr = 0.000824949
I0630 14:46:41.800009 30262 solver.cpp:228] Iteration 2950, loss = 0.29407
I0630 14:46:41.800106 30262 solver.cpp:244]     Train net output #0: loss = 0.29407 (* 1 = 0.29407 loss)
I0630 14:46:41.800120 30262 sgd_solver.cpp:106] Iteration 2950, lr = 0.000823754
I0630 14:48:00.984895 30262 solver.cpp:228] Iteration 2975, loss = 0.248436
I0630 14:48:00.985005 30262 solver.cpp:244]     Train net output #0: loss = 0.248436 (* 1 = 0.248436 loss)
I0630 14:48:00.985019 30262 sgd_solver.cpp:106] Iteration 2975, lr = 0.000822564
I0630 14:49:14.783692 30262 solver.cpp:454] Snapshotting to binary proto file fish_net_pretrain_output_iter_3000.caffemodel
I0630 14:49:16.304467 30262 sgd_solver.cpp:273] Snapshotting solver state to binary proto file fish_net_pretrain_output_iter_3000.solverstate
I0630 14:49:16.304867 30262 solver.cpp:337] Iteration 3000, Testing net (#0)
I0630 14:49:16.304893 30262 net.cpp:684] Ignoring source layer training_cells
I0630 14:49:16.304903 30262 net.cpp:684] Ignoring source layer drop1
I0630 14:49:27.945482 30262 solver.cpp:404]     Test net output #0: accuracy = 0.94375
I0630 14:49:27.945533 30262 solver.cpp:404]     Test net output #1: loss = 0.167891 (* 1 = 0.167891 loss)
I0630 14:49:29.858330 30262 solver.cpp:228] Iteration 3000, loss = 0.128559
I0630 14:49:29.858373 30262 solver.cpp:244]     Train net output #0: loss = 0.128559 (* 1 = 0.128559 loss)
I0630 14:49:29.858384 30262 sgd_solver.cpp:106] Iteration 3000, lr = 0.000821377
I0630 14:50:48.867923 30262 solver.cpp:228] Iteration 3025, loss = 0.167197
I0630 14:50:48.868032 30262 solver.cpp:244]     Train net output #0: loss = 0.167197 (* 1 = 0.167197 loss)
I0630 14:50:48.868046 30262 sgd_solver.cpp:106] Iteration 3025, lr = 0.000820194
I0630 14:52:07.113204 30262 solver.cpp:228] Iteration 3050, loss = 0.261578
I0630 14:52:07.113307 30262 solver.cpp:244]     Train net output #0: loss = 0.261579 (* 1 = 0.261579 loss)
I0630 14:52:07.113318 30262 sgd_solver.cpp:106] Iteration 3050, lr = 0.000819015
I0630 14:53:26.710369 30262 solver.cpp:228] Iteration 3075, loss = 0.160292
I0630 14:53:26.710479 30262 solver.cpp:244]     Train net output #0: loss = 0.160293 (* 1 = 0.160293 loss)
I0630 14:53:26.710494 30262 sgd_solver.cpp:106] Iteration 3075, lr = 0.000817841
I0630 14:54:46.631103 30262 solver.cpp:228] Iteration 3100, loss = 0.31907
I0630 14:54:46.631211 30262 solver.cpp:244]     Train net output #0: loss = 0.31907 (* 1 = 0.31907 loss)
I0630 14:54:46.631224 30262 sgd_solver.cpp:106] Iteration 3100, lr = 0.00081667
I0630 14:56:06.071332 30262 solver.cpp:228] Iteration 3125, loss = 0.0853246
I0630 14:56:06.071434 30262 solver.cpp:244]     Train net output #0: loss = 0.0853249 (* 1 = 0.0853249 loss)
I0630 14:56:06.071447 30262 sgd_solver.cpp:106] Iteration 3125, lr = 0.000815503
I0630 14:57:26.538373 30262 solver.cpp:228] Iteration 3150, loss = 0.219961
I0630 14:57:26.538470 30262 solver.cpp:244]     Train net output #0: loss = 0.219962 (* 1 = 0.219962 loss)
I0630 14:57:26.538482 30262 sgd_solver.cpp:106] Iteration 3150, lr = 0.00081434
I0630 14:58:46.050158 30262 solver.cpp:228] Iteration 3175, loss = 0.140594
I0630 14:58:46.050256 30262 solver.cpp:244]     Train net output #0: loss = 0.140594 (* 1 = 0.140594 loss)
I0630 14:58:46.050271 30262 sgd_solver.cpp:106] Iteration 3175, lr = 0.000813181
I0630 15:00:04.952050 30262 solver.cpp:228] Iteration 3200, loss = 0.244017
I0630 15:00:04.952142 30262 solver.cpp:244]     Train net output #0: loss = 0.244018 (* 1 = 0.244018 loss)
I0630 15:00:04.952155 30262 sgd_solver.cpp:106] Iteration 3200, lr = 0.000812025
I0630 15:01:24.365104 30262 solver.cpp:228] Iteration 3225, loss = 0.202917
I0630 15:01:24.365222 30262 solver.cpp:244]     Train net output #0: loss = 0.202918 (* 1 = 0.202918 loss)
I0630 15:01:24.365236 30262 sgd_solver.cpp:106] Iteration 3225, lr = 0.000810874
I0630 15:02:44.244527 30262 solver.cpp:228] Iteration 3250, loss = 0.290201
I0630 15:02:44.244631 30262 solver.cpp:244]     Train net output #0: loss = 0.290201 (* 1 = 0.290201 loss)
I0630 15:02:44.244644 30262 sgd_solver.cpp:106] Iteration 3250, lr = 0.000809726
I0630 15:04:04.388067 30262 solver.cpp:228] Iteration 3275, loss = 0.232375
I0630 15:04:04.388160 30262 solver.cpp:244]     Train net output #0: loss = 0.232375 (* 1 = 0.232375 loss)
I0630 15:04:04.388173 30262 sgd_solver.cpp:106] Iteration 3275, lr = 0.000808582
I0630 15:05:24.747781 30262 solver.cpp:228] Iteration 3300, loss = 0.163034
I0630 15:05:24.747880 30262 solver.cpp:244]     Train net output #0: loss = 0.163035 (* 1 = 0.163035 loss)
I0630 15:05:24.747900 30262 sgd_solver.cpp:106] Iteration 3300, lr = 0.000807442
I0630 15:06:49.534936 30262 solver.cpp:228] Iteration 3325, loss = 0.300522
I0630 15:06:49.535038 30262 solver.cpp:244]     Train net output #0: loss = 0.300522 (* 1 = 0.300522 loss)
I0630 15:06:49.535050 30262 sgd_solver.cpp:106] Iteration 3325, lr = 0.000806305
I0630 15:08:13.741010 30262 solver.cpp:228] Iteration 3350, loss = 0.161513
I0630 15:08:13.741119 30262 solver.cpp:244]     Train net output #0: loss = 0.161513 (* 1 = 0.161513 loss)
I0630 15:08:13.741137 30262 sgd_solver.cpp:106] Iteration 3350, lr = 0.000805173
I0630 15:09:37.185395 30262 solver.cpp:228] Iteration 3375, loss = 0.109362
I0630 15:09:37.185488 30262 solver.cpp:244]     Train net output #0: loss = 0.109362 (* 1 = 0.109362 loss)
I0630 15:09:37.185502 30262 sgd_solver.cpp:106] Iteration 3375, lr = 0.000804044
I0630 15:11:01.248217 30262 solver.cpp:228] Iteration 3400, loss = 0.126712
I0630 15:11:01.248322 30262 solver.cpp:244]     Train net output #0: loss = 0.126712 (* 1 = 0.126712 loss)
I0630 15:11:01.248337 30262 sgd_solver.cpp:106] Iteration 3400, lr = 0.000802918
I0630 15:12:22.181565 30262 solver.cpp:228] Iteration 3425, loss = 0.520677
I0630 15:12:22.181639 30262 solver.cpp:244]     Train net output #0: loss = 0.520677 (* 1 = 0.520677 loss)
I0630 15:12:22.181651 30262 sgd_solver.cpp:106] Iteration 3425, lr = 0.000801797
I0630 15:13:44.814400 30262 solver.cpp:228] Iteration 3450, loss = 0.218008
I0630 15:13:44.814486 30262 solver.cpp:244]     Train net output #0: loss = 0.218008 (* 1 = 0.218008 loss)
I0630 15:13:44.814497 30262 sgd_solver.cpp:106] Iteration 3450, lr = 0.000800679
I0630 15:15:10.643229 30262 solver.cpp:228] Iteration 3475, loss = 0.236787
I0630 15:15:10.643332 30262 solver.cpp:244]     Train net output #0: loss = 0.236787 (* 1 = 0.236787 loss)
I0630 15:15:10.643352 30262 sgd_solver.cpp:106] Iteration 3475, lr = 0.000799564
I0630 15:16:29.339061 30262 solver.cpp:337] Iteration 3500, Testing net (#0)
I0630 15:16:29.339164 30262 net.cpp:684] Ignoring source layer training_cells
I0630 15:16:29.339177 30262 net.cpp:684] Ignoring source layer drop1
I0630 15:16:43.489889 30262 solver.cpp:404]     Test net output #0: accuracy = 0.951953
I0630 15:16:43.489941 30262 solver.cpp:404]     Test net output #1: loss = 0.155469 (* 1 = 0.155469 loss)
I0630 15:16:45.133090 30262 solver.cpp:228] Iteration 3500, loss = 0.199694
I0630 15:16:45.133143 30262 solver.cpp:244]     Train net output #0: loss = 0.199695 (* 1 = 0.199695 loss)
I0630 15:16:45.133157 30262 sgd_solver.cpp:106] Iteration 3500, lr = 0.000798454
I0630 15:18:04.092563 30262 solver.cpp:228] Iteration 3525, loss = 0.165959
I0630 15:18:04.092667 30262 solver.cpp:244]     Train net output #0: loss = 0.165959 (* 1 = 0.165959 loss)
I0630 15:18:04.092679 30262 sgd_solver.cpp:106] Iteration 3525, lr = 0.000797346
I0630 15:19:25.798199 30262 solver.cpp:228] Iteration 3550, loss = 0.122438
I0630 15:19:25.798322 30262 solver.cpp:244]     Train net output #0: loss = 0.122438 (* 1 = 0.122438 loss)
I0630 15:19:25.798341 30262 sgd_solver.cpp:106] Iteration 3550, lr = 0.000796243
I0630 15:20:50.165797 30262 solver.cpp:228] Iteration 3575, loss = 0.209686
I0630 15:20:50.165918 30262 solver.cpp:244]     Train net output #0: loss = 0.209686 (* 1 = 0.209686 loss)
I0630 15:20:50.165932 30262 sgd_solver.cpp:106] Iteration 3575, lr = 0.000795143
I0630 15:22:12.107991 30262 solver.cpp:228] Iteration 3600, loss = 0.19857
I0630 15:22:12.108131 30262 solver.cpp:244]     Train net output #0: loss = 0.19857 (* 1 = 0.19857 loss)
I0630 15:22:12.108147 30262 sgd_solver.cpp:106] Iteration 3600, lr = 0.000794046
I0630 15:23:14.168287 30262 solver.cpp:228] Iteration 3625, loss = 0.137101
I0630 15:23:14.168380 30262 solver.cpp:244]     Train net output #0: loss = 0.137101 (* 1 = 0.137101 loss)
I0630 15:23:14.168393 30262 sgd_solver.cpp:106] Iteration 3625, lr = 0.000792953
I0630 15:23:56.606771 30262 solver.cpp:228] Iteration 3650, loss = 0.166806
I0630 15:23:56.606873 30262 solver.cpp:244]     Train net output #0: loss = 0.166806 (* 1 = 0.166806 loss)
I0630 15:23:56.606889 30262 sgd_solver.cpp:106] Iteration 3650, lr = 0.000791864
I0630 15:24:38.238842 30262 solver.cpp:228] Iteration 3675, loss = 0.120694
I0630 15:24:38.238941 30262 solver.cpp:244]     Train net output #0: loss = 0.120695 (* 1 = 0.120695 loss)
I0630 15:24:38.238955 30262 sgd_solver.cpp:106] Iteration 3675, lr = 0.000790778
I0630 15:25:20.378304 30262 solver.cpp:228] Iteration 3700, loss = 0.207764
I0630 15:25:20.378419 30262 solver.cpp:244]     Train net output #0: loss = 0.207765 (* 1 = 0.207765 loss)
I0630 15:25:20.378440 30262 sgd_solver.cpp:106] Iteration 3700, lr = 0.000789695
I0630 15:26:01.857245 30262 solver.cpp:228] Iteration 3725, loss = 0.296201
I0630 15:26:01.857357 30262 solver.cpp:244]     Train net output #0: loss = 0.296201 (* 1 = 0.296201 loss)
I0630 15:26:01.857372 30262 sgd_solver.cpp:106] Iteration 3725, lr = 0.000788616
I0630 15:26:43.779258 30262 solver.cpp:228] Iteration 3750, loss = 0.0561752
I0630 15:26:43.779371 30262 solver.cpp:244]     Train net output #0: loss = 0.0561754 (* 1 = 0.0561754 loss)
I0630 15:26:43.779387 30262 sgd_solver.cpp:106] Iteration 3750, lr = 0.000787541
I0630 15:27:23.263759 30262 solver.cpp:228] Iteration 3775, loss = 0.0825431
I0630 15:27:23.263864 30262 solver.cpp:244]     Train net output #0: loss = 0.0825434 (* 1 = 0.0825434 loss)
I0630 15:27:23.263876 30262 sgd_solver.cpp:106] Iteration 3775, lr = 0.000786468
I0630 15:28:02.678275 30262 solver.cpp:228] Iteration 3800, loss = 0.15973
I0630 15:28:02.678377 30262 solver.cpp:244]     Train net output #0: loss = 0.15973 (* 1 = 0.15973 loss)
I0630 15:28:02.678392 30262 sgd_solver.cpp:106] Iteration 3800, lr = 0.0007854
I0630 15:28:47.674983 30262 solver.cpp:228] Iteration 3825, loss = 0.270573
I0630 15:28:47.675137 30262 solver.cpp:244]     Train net output #0: loss = 0.270574 (* 1 = 0.270574 loss)
I0630 15:28:47.675153 30262 sgd_solver.cpp:106] Iteration 3825, lr = 0.000784334
I0630 15:29:31.625910 30262 solver.cpp:228] Iteration 3850, loss = 0.173516
I0630 15:29:31.626000 30262 solver.cpp:244]     Train net output #0: loss = 0.173517 (* 1 = 0.173517 loss)
I0630 15:29:31.626013 30262 sgd_solver.cpp:106] Iteration 3850, lr = 0.000783272
I0630 15:30:13.544905 30262 solver.cpp:228] Iteration 3875, loss = 0.0680498
I0630 15:30:13.545018 30262 solver.cpp:244]     Train net output #0: loss = 0.0680501 (* 1 = 0.0680501 loss)
I0630 15:30:13.545030 30262 sgd_solver.cpp:106] Iteration 3875, lr = 0.000782213
I0630 15:30:59.638571 30262 solver.cpp:228] Iteration 3900, loss = 0.215726
I0630 15:30:59.638689 30262 solver.cpp:244]     Train net output #0: loss = 0.215726 (* 1 = 0.215726 loss)
I0630 15:30:59.638705 30262 sgd_solver.cpp:106] Iteration 3900, lr = 0.000781158
I0630 15:31:42.822590 30262 solver.cpp:228] Iteration 3925, loss = 0.122694
I0630 15:31:42.822705 30262 solver.cpp:244]     Train net output #0: loss = 0.122694 (* 1 = 0.122694 loss)
I0630 15:31:42.822722 30262 sgd_solver.cpp:106] Iteration 3925, lr = 0.000780106
I0630 15:32:29.312885 30262 solver.cpp:228] Iteration 3950, loss = 0.200285
I0630 15:32:29.312985 30262 solver.cpp:244]     Train net output #0: loss = 0.200286 (* 1 = 0.200286 loss)
I0630 15:32:29.312997 30262 sgd_solver.cpp:106] Iteration 3950, lr = 0.000779057
I0630 15:33:13.265301 30262 solver.cpp:228] Iteration 3975, loss = 0.0862629
I0630 15:33:13.265418 30262 solver.cpp:244]     Train net output #0: loss = 0.0862632 (* 1 = 0.0862632 loss)
I0630 15:33:13.265430 30262 sgd_solver.cpp:106] Iteration 3975, lr = 0.000778012
I0630 15:33:56.366818 30262 solver.cpp:454] Snapshotting to binary proto file fish_net_pretrain_output_iter_4000.caffemodel
I0630 15:33:57.379830 30262 sgd_solver.cpp:273] Snapshotting solver state to binary proto file fish_net_pretrain_output_iter_4000.solverstate
I0630 15:33:57.380239 30262 solver.cpp:337] Iteration 4000, Testing net (#0)
I0630 15:33:57.380270 30262 net.cpp:684] Ignoring source layer training_cells
I0630 15:33:57.380278 30262 net.cpp:684] Ignoring source layer drop1
I0630 15:34:03.234804 30262 solver.cpp:404]     Test net output #0: accuracy = 0.955078
I0630 15:34:03.234879 30262 solver.cpp:404]     Test net output #1: loss = 0.125717 (* 1 = 0.125717 loss)
I0630 15:34:04.123208 30262 solver.cpp:228] Iteration 4000, loss = 0.101194
I0630 15:34:04.125301 30262 solver.cpp:244]     Train net output #0: loss = 0.101195 (* 1 = 0.101195 loss)
I0630 15:34:04.125324 30262 sgd_solver.cpp:106] Iteration 4000, lr = 0.00077697
I0630 15:34:48.926321 30262 solver.cpp:228] Iteration 4025, loss = 0.266014
I0630 15:34:48.926426 30262 solver.cpp:244]     Train net output #0: loss = 0.266014 (* 1 = 0.266014 loss)
I0630 15:34:48.926439 30262 sgd_solver.cpp:106] Iteration 4025, lr = 0.000775931
I0630 15:35:32.174222 30262 solver.cpp:228] Iteration 4050, loss = 0.0932432
I0630 15:35:32.174316 30262 solver.cpp:244]     Train net output #0: loss = 0.0932436 (* 1 = 0.0932436 loss)
I0630 15:35:32.174329 30262 sgd_solver.cpp:106] Iteration 4050, lr = 0.000774895
I0630 15:36:18.026439 30262 solver.cpp:228] Iteration 4075, loss = 0.32823
I0630 15:36:18.026593 30262 solver.cpp:244]     Train net output #0: loss = 0.32823 (* 1 = 0.32823 loss)
I0630 15:36:18.026608 30262 sgd_solver.cpp:106] Iteration 4075, lr = 0.000773862
I0630 15:37:02.964109 30262 solver.cpp:228] Iteration 4100, loss = 0.149823
I0630 15:37:02.964224 30262 solver.cpp:244]     Train net output #0: loss = 0.149823 (* 1 = 0.149823 loss)
I0630 15:37:02.964239 30262 sgd_solver.cpp:106] Iteration 4100, lr = 0.000772833
I0630 15:37:48.537801 30262 solver.cpp:228] Iteration 4125, loss = 0.293206
I0630 15:37:48.537926 30262 solver.cpp:244]     Train net output #0: loss = 0.293206 (* 1 = 0.293206 loss)
I0630 15:37:48.537940 30262 sgd_solver.cpp:106] Iteration 4125, lr = 0.000771807
I0630 15:38:32.401242 30262 solver.cpp:228] Iteration 4150, loss = 0.227218
I0630 15:38:32.401331 30262 solver.cpp:244]     Train net output #0: loss = 0.227218 (* 1 = 0.227218 loss)
I0630 15:38:32.401342 30262 sgd_solver.cpp:106] Iteration 4150, lr = 0.000770784
I0630 15:39:19.300227 30262 solver.cpp:228] Iteration 4175, loss = 0.230902
I0630 15:39:19.300339 30262 solver.cpp:244]     Train net output #0: loss = 0.230903 (* 1 = 0.230903 loss)
I0630 15:39:19.300354 30262 sgd_solver.cpp:106] Iteration 4175, lr = 0.000769764
I0630 15:40:05.333889 30262 solver.cpp:228] Iteration 4200, loss = 0.107723
I0630 15:40:05.333995 30262 solver.cpp:244]     Train net output #0: loss = 0.107723 (* 1 = 0.107723 loss)
I0630 15:40:05.334010 30262 sgd_solver.cpp:106] Iteration 4200, lr = 0.000768748
I0630 15:40:50.138311 30262 solver.cpp:228] Iteration 4225, loss = 0.0890505
I0630 15:40:50.138422 30262 solver.cpp:244]     Train net output #0: loss = 0.0890509 (* 1 = 0.0890509 loss)
I0630 15:40:50.138435 30262 sgd_solver.cpp:106] Iteration 4225, lr = 0.000767734
I0630 15:41:37.282485 30262 solver.cpp:228] Iteration 4250, loss = 0.0622211
I0630 15:41:37.282588 30262 solver.cpp:244]     Train net output #0: loss = 0.0622214 (* 1 = 0.0622214 loss)
I0630 15:41:37.282599 30262 sgd_solver.cpp:106] Iteration 4250, lr = 0.000766724
I0630 15:42:17.236508 30262 solver.cpp:228] Iteration 4275, loss = 0.216423
I0630 15:42:17.236624 30262 solver.cpp:244]     Train net output #0: loss = 0.216423 (* 1 = 0.216423 loss)
I0630 15:42:17.236639 30262 sgd_solver.cpp:106] Iteration 4275, lr = 0.000765716
I0630 15:42:57.796329 30262 solver.cpp:228] Iteration 4300, loss = 0.144857
I0630 15:42:57.796453 30262 solver.cpp:244]     Train net output #0: loss = 0.144858 (* 1 = 0.144858 loss)
I0630 15:42:57.796465 30262 sgd_solver.cpp:106] Iteration 4300, lr = 0.000764712
I0630 15:43:38.711786 30262 solver.cpp:228] Iteration 4325, loss = 0.471221
I0630 15:43:38.711880 30262 solver.cpp:244]     Train net output #0: loss = 0.471222 (* 1 = 0.471222 loss)
I0630 15:43:38.711894 30262 sgd_solver.cpp:106] Iteration 4325, lr = 0.000763711
I0630 15:44:18.659070 30262 solver.cpp:228] Iteration 4350, loss = 0.136373
I0630 15:44:18.659162 30262 solver.cpp:244]     Train net output #0: loss = 0.136373 (* 1 = 0.136373 loss)
I0630 15:44:18.659174 30262 sgd_solver.cpp:106] Iteration 4350, lr = 0.000762713
I0630 15:44:58.860654 30262 solver.cpp:228] Iteration 4375, loss = 0.299028
I0630 15:44:58.860750 30262 solver.cpp:244]     Train net output #0: loss = 0.299028 (* 1 = 0.299028 loss)
I0630 15:44:58.860764 30262 sgd_solver.cpp:106] Iteration 4375, lr = 0.000761718
I0630 15:45:39.756134 30262 solver.cpp:228] Iteration 4400, loss = 0.15998
I0630 15:45:39.756208 30262 solver.cpp:244]     Train net output #0: loss = 0.15998 (* 1 = 0.15998 loss)
I0630 15:45:39.756219 30262 sgd_solver.cpp:106] Iteration 4400, lr = 0.000760726
I0630 15:46:20.434058 30262 solver.cpp:228] Iteration 4425, loss = 0.134731
I0630 15:46:20.434156 30262 solver.cpp:244]     Train net output #0: loss = 0.134731 (* 1 = 0.134731 loss)
I0630 15:46:20.434173 30262 sgd_solver.cpp:106] Iteration 4425, lr = 0.000759737
I0630 15:47:01.120812 30262 solver.cpp:228] Iteration 4450, loss = 0.115887
I0630 15:47:01.120903 30262 solver.cpp:244]     Train net output #0: loss = 0.115887 (* 1 = 0.115887 loss)
I0630 15:47:01.120921 30262 sgd_solver.cpp:106] Iteration 4450, lr = 0.000758751
I0630 15:47:22.463799 30262 solver.cpp:454] Snapshotting to binary proto file fish_net_pretrain_output_iter_4464.caffemodel
I0630 15:47:23.386018 30262 sgd_solver.cpp:273] Snapshotting solver state to binary proto file fish_net_pretrain_output_iter_4464.solverstate
I0630 15:47:23.386477 30262 solver.cpp:301] Optimization stopped early.
I0630 15:47:23.386504 30262 caffe.cpp:222] Optimization Done.
