Log file created at: 2016/07/07 14:12:56
Running on machine: betty
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0707 14:12:56.634491 10409 caffe.cpp:185] Using GPUs 0
I0707 14:12:56.733741 10409 caffe.cpp:190] GPU 0: GeForce GTX 760
I0707 14:12:56.868541 10409 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 1000
base_lr: 0.001
display: 25
max_iter: 100000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.4
weight_decay: 0.0005
snapshot: 1000
snapshot_prefix: "fish_net_memory_map_output"
solver_mode: GPU
device_id: 0
net: "/home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_memory_map_trainer.prototxt"
I0707 14:12:56.868757 10409 solver.cpp:91] Creating training net from net file: /home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_memory_map_trainer.prototxt
I0707 14:12:56.869102 10409 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer testing_cells
I0707 14:12:56.869120 10409 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0707 14:12:56.869199 10409 net.cpp:49] Initializing net from parameters: 
name: "fish_filter"
state {
  phase: TRAIN
}
layer {
  name: "training_cells"
  type: "Python"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "fisherman.caffe_layers"
    layer: "DataMapLayer"
    param_str: "{\'tops\': [\'image\', \'label\'], \'data_dir\': \'/home/sam/code/fisherman/data/dense_labelling_k149/\', \'split\': \'train\', \'samples_per_class\': 256, \'kernel\': 149}"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "image"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 15
    kernel_size: 15
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 5
    stride: 5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0707 14:12:56.869510 10409 layer_factory.hpp:77] Creating layer training_cells
I0707 14:12:57.678874 10409 net.cpp:91] Creating Layer training_cells
I0707 14:12:57.678910 10409 net.cpp:399] training_cells -> image
I0707 14:12:57.678933 10409 net.cpp:399] training_cells -> label
I0707 14:14:37.228579 10409 net.cpp:141] Setting up training_cells
I0707 14:14:37.228632 10409 net.cpp:148] Top shape: 512 2 149 149 (22733824)
I0707 14:14:37.228639 10409 net.cpp:148] Top shape: 512 (512)
I0707 14:14:37.228643 10409 net.cpp:156] Memory required for data: 90937344
I0707 14:14:37.228654 10409 layer_factory.hpp:77] Creating layer conv1
I0707 14:14:37.228674 10409 net.cpp:91] Creating Layer conv1
I0707 14:14:37.228680 10409 net.cpp:425] conv1 <- image
I0707 14:14:37.228693 10409 net.cpp:399] conv1 -> conv1
I0707 14:14:37.229815 10409 net.cpp:141] Setting up conv1
I0707 14:14:37.229838 10409 net.cpp:148] Top shape: 512 15 135 135 (139968000)
I0707 14:14:37.229843 10409 net.cpp:156] Memory required for data: 650809344
I0707 14:14:37.229868 10409 layer_factory.hpp:77] Creating layer pool1
I0707 14:14:37.229877 10409 net.cpp:91] Creating Layer pool1
I0707 14:14:37.229882 10409 net.cpp:425] pool1 <- conv1
I0707 14:14:37.229897 10409 net.cpp:399] pool1 -> pool1
I0707 14:14:37.229943 10409 net.cpp:141] Setting up pool1
I0707 14:14:37.229950 10409 net.cpp:148] Top shape: 512 15 27 27 (5598720)
I0707 14:14:37.229955 10409 net.cpp:156] Memory required for data: 673204224
I0707 14:14:37.229959 10409 layer_factory.hpp:77] Creating layer conv2
I0707 14:14:37.229969 10409 net.cpp:91] Creating Layer conv2
I0707 14:14:37.229974 10409 net.cpp:425] conv2 <- pool1
I0707 14:14:37.229979 10409 net.cpp:399] conv2 -> conv2
I0707 14:14:37.232631 10409 net.cpp:141] Setting up conv2
I0707 14:14:37.232645 10409 net.cpp:148] Top shape: 512 5 21 21 (1128960)
I0707 14:14:37.232651 10409 net.cpp:156] Memory required for data: 677720064
I0707 14:14:37.232661 10409 layer_factory.hpp:77] Creating layer pool2
I0707 14:14:37.232668 10409 net.cpp:91] Creating Layer pool2
I0707 14:14:37.232673 10409 net.cpp:425] pool2 <- conv2
I0707 14:14:37.232679 10409 net.cpp:399] pool2 -> pool2
I0707 14:14:37.232707 10409 net.cpp:141] Setting up pool2
I0707 14:14:37.232712 10409 net.cpp:148] Top shape: 512 5 7 7 (125440)
I0707 14:14:37.232717 10409 net.cpp:156] Memory required for data: 678221824
I0707 14:14:37.232722 10409 layer_factory.hpp:77] Creating layer ip1
I0707 14:14:37.232739 10409 net.cpp:91] Creating Layer ip1
I0707 14:14:37.232744 10409 net.cpp:425] ip1 <- pool2
I0707 14:14:37.232750 10409 net.cpp:399] ip1 -> ip1
I0707 14:14:37.232857 10409 net.cpp:141] Setting up ip1
I0707 14:14:37.232864 10409 net.cpp:148] Top shape: 512 32 (16384)
I0707 14:14:37.232869 10409 net.cpp:156] Memory required for data: 678287360
I0707 14:14:37.232877 10409 layer_factory.hpp:77] Creating layer relu1
I0707 14:14:37.232883 10409 net.cpp:91] Creating Layer relu1
I0707 14:14:37.232888 10409 net.cpp:425] relu1 <- ip1
I0707 14:14:37.232893 10409 net.cpp:386] relu1 -> ip1 (in-place)
I0707 14:14:37.232902 10409 net.cpp:141] Setting up relu1
I0707 14:14:37.232906 10409 net.cpp:148] Top shape: 512 32 (16384)
I0707 14:14:37.232911 10409 net.cpp:156] Memory required for data: 678352896
I0707 14:14:37.232915 10409 layer_factory.hpp:77] Creating layer drop1
I0707 14:14:37.232925 10409 net.cpp:91] Creating Layer drop1
I0707 14:14:37.232930 10409 net.cpp:425] drop1 <- ip1
I0707 14:14:37.232936 10409 net.cpp:386] drop1 -> ip1 (in-place)
I0707 14:14:37.232954 10409 net.cpp:141] Setting up drop1
I0707 14:14:37.232960 10409 net.cpp:148] Top shape: 512 32 (16384)
I0707 14:14:37.232965 10409 net.cpp:156] Memory required for data: 678418432
I0707 14:14:37.232969 10409 layer_factory.hpp:77] Creating layer ip2
I0707 14:14:37.232976 10409 net.cpp:91] Creating Layer ip2
I0707 14:14:37.232981 10409 net.cpp:425] ip2 <- ip1
I0707 14:14:37.232987 10409 net.cpp:399] ip2 -> ip2
I0707 14:14:37.233052 10409 net.cpp:141] Setting up ip2
I0707 14:14:37.233060 10409 net.cpp:148] Top shape: 512 2 (1024)
I0707 14:14:37.233064 10409 net.cpp:156] Memory required for data: 678422528
I0707 14:14:37.233072 10409 layer_factory.hpp:77] Creating layer loss
I0707 14:14:37.233078 10409 net.cpp:91] Creating Layer loss
I0707 14:14:37.233083 10409 net.cpp:425] loss <- ip2
I0707 14:14:37.233088 10409 net.cpp:425] loss <- label
I0707 14:14:37.233105 10409 net.cpp:399] loss -> loss
I0707 14:14:37.233132 10409 layer_factory.hpp:77] Creating layer loss
I0707 14:14:37.233247 10409 net.cpp:141] Setting up loss
I0707 14:14:37.233254 10409 net.cpp:148] Top shape: (1)
I0707 14:14:37.233258 10409 net.cpp:151]     with loss weight 1
I0707 14:14:37.233271 10409 net.cpp:156] Memory required for data: 678422532
I0707 14:14:37.233274 10409 net.cpp:217] loss needs backward computation.
I0707 14:14:37.233278 10409 net.cpp:217] ip2 needs backward computation.
I0707 14:14:37.233279 10409 net.cpp:217] drop1 needs backward computation.
I0707 14:14:37.233283 10409 net.cpp:217] relu1 needs backward computation.
I0707 14:14:37.233284 10409 net.cpp:217] ip1 needs backward computation.
I0707 14:14:37.233288 10409 net.cpp:217] pool2 needs backward computation.
I0707 14:14:37.233290 10409 net.cpp:217] conv2 needs backward computation.
I0707 14:14:37.233294 10409 net.cpp:217] pool1 needs backward computation.
I0707 14:14:37.233295 10409 net.cpp:217] conv1 needs backward computation.
I0707 14:14:37.233299 10409 net.cpp:219] training_cells does not need backward computation.
I0707 14:14:37.233301 10409 net.cpp:261] This network produces output loss
I0707 14:14:37.233309 10409 net.cpp:274] Network initialization done.
I0707 14:14:37.233613 10409 solver.cpp:181] Creating test net (#0) specified by net file: /home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_memory_map_trainer.prototxt
I0707 14:14:37.233633 10409 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer training_cells
I0707 14:14:37.233641 10409 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer drop1
I0707 14:14:37.233706 10409 net.cpp:49] Initializing net from parameters: 
name: "fish_filter"
state {
  phase: TEST
}
layer {
  name: "testing_cells"
  type: "Python"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  python_param {
    module: "fisherman.caffe_layers"
    layer: "DataMapLayer"
    param_str: "{\'tops\': [\'image\', \'label\'], \'data_dir\': \'/home/sam/code/fisherman/data/dense_labelling_k149/\', \'split\': \'test\', \'samples_per_class\': 256, \'kernel\': 149}"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "image"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 15
    kernel_size: 15
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 5
    stride: 5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0707 14:14:37.233777 10409 layer_factory.hpp:77] Creating layer testing_cells
I0707 14:14:37.233815 10409 net.cpp:91] Creating Layer testing_cells
I0707 14:14:37.233820 10409 net.cpp:399] testing_cells -> image
I0707 14:14:37.233853 10409 net.cpp:399] testing_cells -> label
I0707 14:15:26.290714 10409 net.cpp:141] Setting up testing_cells
I0707 14:15:26.290794 10409 net.cpp:148] Top shape: 512 2 149 149 (22733824)
I0707 14:15:26.290802 10409 net.cpp:148] Top shape: 512 (512)
I0707 14:15:26.290807 10409 net.cpp:156] Memory required for data: 90937344
I0707 14:15:26.290814 10409 layer_factory.hpp:77] Creating layer label_testing_cells_1_split
I0707 14:15:26.290827 10409 net.cpp:91] Creating Layer label_testing_cells_1_split
I0707 14:15:26.290832 10409 net.cpp:425] label_testing_cells_1_split <- label
I0707 14:15:26.290839 10409 net.cpp:399] label_testing_cells_1_split -> label_testing_cells_1_split_0
I0707 14:15:26.290850 10409 net.cpp:399] label_testing_cells_1_split -> label_testing_cells_1_split_1
I0707 14:15:26.290882 10409 net.cpp:141] Setting up label_testing_cells_1_split
I0707 14:15:26.290890 10409 net.cpp:148] Top shape: 512 (512)
I0707 14:15:26.290895 10409 net.cpp:148] Top shape: 512 (512)
I0707 14:15:26.290899 10409 net.cpp:156] Memory required for data: 90941440
I0707 14:15:26.290904 10409 layer_factory.hpp:77] Creating layer conv1
I0707 14:15:26.290917 10409 net.cpp:91] Creating Layer conv1
I0707 14:15:26.290922 10409 net.cpp:425] conv1 <- image
I0707 14:15:26.290930 10409 net.cpp:399] conv1 -> conv1
I0707 14:15:26.291128 10409 net.cpp:141] Setting up conv1
I0707 14:15:26.291137 10409 net.cpp:148] Top shape: 512 15 135 135 (139968000)
I0707 14:15:26.291141 10409 net.cpp:156] Memory required for data: 650813440
I0707 14:15:26.291152 10409 layer_factory.hpp:77] Creating layer pool1
I0707 14:15:26.291162 10409 net.cpp:91] Creating Layer pool1
I0707 14:15:26.291165 10409 net.cpp:425] pool1 <- conv1
I0707 14:15:26.291172 10409 net.cpp:399] pool1 -> pool1
I0707 14:15:26.291198 10409 net.cpp:141] Setting up pool1
I0707 14:15:26.291205 10409 net.cpp:148] Top shape: 512 15 27 27 (5598720)
I0707 14:15:26.291209 10409 net.cpp:156] Memory required for data: 673208320
I0707 14:15:26.291214 10409 layer_factory.hpp:77] Creating layer conv2
I0707 14:15:26.291224 10409 net.cpp:91] Creating Layer conv2
I0707 14:15:26.291227 10409 net.cpp:425] conv2 <- pool1
I0707 14:15:26.291234 10409 net.cpp:399] conv2 -> conv2
I0707 14:15:26.291404 10409 net.cpp:141] Setting up conv2
I0707 14:15:26.291412 10409 net.cpp:148] Top shape: 512 5 21 21 (1128960)
I0707 14:15:26.291417 10409 net.cpp:156] Memory required for data: 677724160
I0707 14:15:26.291425 10409 layer_factory.hpp:77] Creating layer pool2
I0707 14:15:26.291431 10409 net.cpp:91] Creating Layer pool2
I0707 14:15:26.291436 10409 net.cpp:425] pool2 <- conv2
I0707 14:15:26.291442 10409 net.cpp:399] pool2 -> pool2
I0707 14:15:26.291465 10409 net.cpp:141] Setting up pool2
I0707 14:15:26.291471 10409 net.cpp:148] Top shape: 512 5 7 7 (125440)
I0707 14:15:26.291476 10409 net.cpp:156] Memory required for data: 678225920
I0707 14:15:26.291481 10409 layer_factory.hpp:77] Creating layer ip1
I0707 14:15:26.291488 10409 net.cpp:91] Creating Layer ip1
I0707 14:15:26.291493 10409 net.cpp:425] ip1 <- pool2
I0707 14:15:26.291498 10409 net.cpp:399] ip1 -> ip1
I0707 14:15:26.291604 10409 net.cpp:141] Setting up ip1
I0707 14:15:26.291612 10409 net.cpp:148] Top shape: 512 32 (16384)
I0707 14:15:26.291616 10409 net.cpp:156] Memory required for data: 678291456
I0707 14:15:26.291625 10409 layer_factory.hpp:77] Creating layer relu1
I0707 14:15:26.291631 10409 net.cpp:91] Creating Layer relu1
I0707 14:15:26.291646 10409 net.cpp:425] relu1 <- ip1
I0707 14:15:26.291652 10409 net.cpp:386] relu1 -> ip1 (in-place)
I0707 14:15:26.291658 10409 net.cpp:141] Setting up relu1
I0707 14:15:26.291664 10409 net.cpp:148] Top shape: 512 32 (16384)
I0707 14:15:26.291668 10409 net.cpp:156] Memory required for data: 678356992
I0707 14:15:26.291672 10409 layer_factory.hpp:77] Creating layer ip2
I0707 14:15:26.291689 10409 net.cpp:91] Creating Layer ip2
I0707 14:15:26.291704 10409 net.cpp:425] ip2 <- ip1
I0707 14:15:26.291710 10409 net.cpp:399] ip2 -> ip2
I0707 14:15:26.291785 10409 net.cpp:141] Setting up ip2
I0707 14:15:26.291792 10409 net.cpp:148] Top shape: 512 2 (1024)
I0707 14:15:26.291797 10409 net.cpp:156] Memory required for data: 678361088
I0707 14:15:26.291803 10409 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0707 14:15:26.291837 10409 net.cpp:91] Creating Layer ip2_ip2_0_split
I0707 14:15:26.291842 10409 net.cpp:425] ip2_ip2_0_split <- ip2
I0707 14:15:26.291848 10409 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0707 14:15:26.291856 10409 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0707 14:15:26.291879 10409 net.cpp:141] Setting up ip2_ip2_0_split
I0707 14:15:26.291887 10409 net.cpp:148] Top shape: 512 2 (1024)
I0707 14:15:26.291892 10409 net.cpp:148] Top shape: 512 2 (1024)
I0707 14:15:26.291895 10409 net.cpp:156] Memory required for data: 678369280
I0707 14:15:26.291900 10409 layer_factory.hpp:77] Creating layer accuracy
I0707 14:15:26.291913 10409 net.cpp:91] Creating Layer accuracy
I0707 14:15:26.291918 10409 net.cpp:425] accuracy <- ip2_ip2_0_split_0
I0707 14:15:26.291923 10409 net.cpp:425] accuracy <- label_testing_cells_1_split_0
I0707 14:15:26.291929 10409 net.cpp:399] accuracy -> accuracy
I0707 14:15:26.291937 10409 net.cpp:141] Setting up accuracy
I0707 14:15:26.291944 10409 net.cpp:148] Top shape: (1)
I0707 14:15:26.291947 10409 net.cpp:156] Memory required for data: 678369284
I0707 14:15:26.291952 10409 layer_factory.hpp:77] Creating layer loss
I0707 14:15:26.291959 10409 net.cpp:91] Creating Layer loss
I0707 14:15:26.291963 10409 net.cpp:425] loss <- ip2_ip2_0_split_1
I0707 14:15:26.291968 10409 net.cpp:425] loss <- label_testing_cells_1_split_1
I0707 14:15:26.291973 10409 net.cpp:399] loss -> loss
I0707 14:15:26.291982 10409 layer_factory.hpp:77] Creating layer loss
I0707 14:15:26.292032 10409 net.cpp:141] Setting up loss
I0707 14:15:26.292038 10409 net.cpp:148] Top shape: (1)
I0707 14:15:26.292042 10409 net.cpp:151]     with loss weight 1
I0707 14:15:26.292052 10409 net.cpp:156] Memory required for data: 678369288
I0707 14:15:26.292057 10409 net.cpp:217] loss needs backward computation.
I0707 14:15:26.292062 10409 net.cpp:219] accuracy does not need backward computation.
I0707 14:15:26.292067 10409 net.cpp:217] ip2_ip2_0_split needs backward computation.
I0707 14:15:26.292071 10409 net.cpp:217] ip2 needs backward computation.
I0707 14:15:26.292075 10409 net.cpp:217] relu1 needs backward computation.
I0707 14:15:26.292080 10409 net.cpp:217] ip1 needs backward computation.
I0707 14:15:26.292084 10409 net.cpp:217] pool2 needs backward computation.
I0707 14:15:26.292088 10409 net.cpp:217] conv2 needs backward computation.
I0707 14:15:26.292093 10409 net.cpp:217] pool1 needs backward computation.
I0707 14:15:26.292098 10409 net.cpp:217] conv1 needs backward computation.
I0707 14:15:26.292103 10409 net.cpp:219] label_testing_cells_1_split does not need backward computation.
I0707 14:15:26.292109 10409 net.cpp:219] testing_cells does not need backward computation.
I0707 14:15:26.292112 10409 net.cpp:261] This network produces output accuracy
I0707 14:15:26.292117 10409 net.cpp:261] This network produces output loss
I0707 14:15:26.292126 10409 net.cpp:274] Network initialization done.
I0707 14:15:26.292177 10409 solver.cpp:60] Solver scaffolding done.
I0707 14:15:26.292346 10409 caffe.cpp:209] Resuming from fish_net_memory_map_output_iter_4110.solverstate
I0707 14:15:26.292630 10409 sgd_solver.cpp:318] SGDSolver: restoring history
I0707 14:15:26.292724 10409 caffe.cpp:219] Starting Optimization
I0707 14:15:26.292732 10409 solver.cpp:279] Solving fish_filter
I0707 14:15:26.292735 10409 solver.cpp:280] Learning Rate Policy: inv
I0707 14:17:48.164546 10409 solver.cpp:228] Iteration 4125, loss = 0.343013
I0707 14:17:48.164679 10409 solver.cpp:244]     Train net output #0: loss = 0.343013 (* 1 = 0.343013 loss)
I0707 14:17:48.164695 10409 sgd_solver.cpp:106] Iteration 4125, lr = 0.000771807
I0707 14:21:22.587236 10409 solver.cpp:228] Iteration 4150, loss = 0.320225
I0707 14:21:22.587337 10409 solver.cpp:244]     Train net output #0: loss = 0.320225 (* 1 = 0.320225 loss)
I0707 14:21:22.587349 10409 sgd_solver.cpp:106] Iteration 4150, lr = 0.000770784
I0707 14:22:31.293015 10409 solver.cpp:454] Snapshotting to binary proto file fish_net_memory_map_output_iter_4159.caffemodel
I0707 14:22:32.349937 10409 sgd_solver.cpp:273] Snapshotting solver state to binary proto file fish_net_memory_map_output_iter_4159.solverstate
I0707 14:22:32.350273 10409 solver.cpp:301] Optimization stopped early.
I0707 14:22:32.350284 10409 caffe.cpp:222] Optimization Done.
