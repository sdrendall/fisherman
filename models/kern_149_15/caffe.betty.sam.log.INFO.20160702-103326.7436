Log file created at: 2016/07/02 10:33:26
Running on machine: betty
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0702 10:33:26.213989  7436 caffe.cpp:185] Using GPUs 0
I0702 10:33:26.291924  7436 caffe.cpp:190] GPU 0: GeForce GTX 760
I0702 10:33:26.421478  7436 solver.cpp:48] Initializing solver from parameters: 
test_iter: 50
test_interval: 500
base_lr: 1e-07
display: 20
max_iter: 300000
lr_policy: "fixed"
momentum: 0.75
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "fish_net_output"
solver_mode: GPU
device_id: 0
net: "/home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_train_test.prototxt"
average_loss: 20
I0702 10:33:26.421689  7436 solver.cpp:91] Creating training net from net file: /home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_train_test.prototxt
I0702 10:33:26.422119  7436 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer testing_cells
I0702 10:33:26.422148  7436 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0702 10:33:26.422224  7436 net.cpp:49] Initializing net from parameters: 
name: "fish_filter"
state {
  phase: TRAIN
}
layer {
  name: "training_cells"
  type: "Python"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "fisherman.caffe_layers"
    layer: "ChunkingFishFovDataLayer"
    param_str: "{\'tops\': [\'image\', \'label\'], \'seed\': 1337, \'data_dir\': \'/home/sam/code/fisherman/data/dense_labelling_same_res/\', \'split\': \'train\', \'n_samples\': 20, \'chunker_params\': {\'chunk_size\': 254, \'window_size\': 1}}"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "image"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 15
    kernel_size: 15
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 5
    stride: 5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "ip_conv1"
  type: "Convolution"
  bottom: "pool2"
  top: "ip_conv_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip_conv_1"
  top: "ip_conv_1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip_conv_1"
  top: "ip_conv_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip_conv2"
  type: "Convolution"
  bottom: "ip_conv_1"
  top: "ip_conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upsample"
  type: "Deconvolution"
  bottom: "ip_conv2"
  top: "upsample"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: false
    kernel_size: 149
    stride: 15
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "upsample"
  bottom: "label"
  top: "loss"
  loss_param {
    normalize: true
  }
}
I0702 10:33:26.422565  7436 layer_factory.hpp:77] Creating layer training_cells
I0702 10:33:27.229362  7436 net.cpp:91] Creating Layer training_cells
I0702 10:33:27.229393  7436 net.cpp:399] training_cells -> image
I0702 10:33:27.229413  7436 net.cpp:399] training_cells -> label
I0702 10:33:27.305857  7436 net.cpp:141] Setting up training_cells
I0702 10:33:27.305892  7436 net.cpp:148] Top shape: 20 2 254 254 (2580640)
I0702 10:33:27.305899  7436 net.cpp:148] Top shape: 20 1 254 254 (1290320)
I0702 10:33:27.305903  7436 net.cpp:156] Memory required for data: 15483840
I0702 10:33:27.305971  7436 layer_factory.hpp:77] Creating layer conv1
I0702 10:33:27.305994  7436 net.cpp:91] Creating Layer conv1
I0702 10:33:27.306001  7436 net.cpp:425] conv1 <- image
I0702 10:33:27.306015  7436 net.cpp:399] conv1 -> conv1
I0702 10:33:27.308543  7436 net.cpp:141] Setting up conv1
I0702 10:33:27.308560  7436 net.cpp:148] Top shape: 20 15 240 240 (17280000)
I0702 10:33:27.308565  7436 net.cpp:156] Memory required for data: 84603840
I0702 10:33:27.308580  7436 layer_factory.hpp:77] Creating layer pool1
I0702 10:33:27.308591  7436 net.cpp:91] Creating Layer pool1
I0702 10:33:27.308598  7436 net.cpp:425] pool1 <- conv1
I0702 10:33:27.308604  7436 net.cpp:399] pool1 -> pool1
I0702 10:33:27.308645  7436 net.cpp:141] Setting up pool1
I0702 10:33:27.308653  7436 net.cpp:148] Top shape: 20 15 48 48 (691200)
I0702 10:33:27.308660  7436 net.cpp:156] Memory required for data: 87368640
I0702 10:33:27.308667  7436 layer_factory.hpp:77] Creating layer conv2
I0702 10:33:27.308678  7436 net.cpp:91] Creating Layer conv2
I0702 10:33:27.308683  7436 net.cpp:425] conv2 <- pool1
I0702 10:33:27.308691  7436 net.cpp:399] conv2 -> conv2
I0702 10:33:27.309140  7436 net.cpp:141] Setting up conv2
I0702 10:33:27.309154  7436 net.cpp:148] Top shape: 20 5 42 42 (176400)
I0702 10:33:27.309160  7436 net.cpp:156] Memory required for data: 88074240
I0702 10:33:27.309175  7436 layer_factory.hpp:77] Creating layer pool2
I0702 10:33:27.309185  7436 net.cpp:91] Creating Layer pool2
I0702 10:33:27.309191  7436 net.cpp:425] pool2 <- conv2
I0702 10:33:27.309198  7436 net.cpp:399] pool2 -> pool2
I0702 10:33:27.309226  7436 net.cpp:141] Setting up pool2
I0702 10:33:27.309233  7436 net.cpp:148] Top shape: 20 5 14 14 (19600)
I0702 10:33:27.309237  7436 net.cpp:156] Memory required for data: 88152640
I0702 10:33:27.309242  7436 layer_factory.hpp:77] Creating layer ip_conv1
I0702 10:33:27.309252  7436 net.cpp:91] Creating Layer ip_conv1
I0702 10:33:27.309257  7436 net.cpp:425] ip_conv1 <- pool2
I0702 10:33:27.309265  7436 net.cpp:399] ip_conv1 -> ip_conv_1
I0702 10:33:27.309448  7436 net.cpp:141] Setting up ip_conv1
I0702 10:33:27.309458  7436 net.cpp:148] Top shape: 20 32 8 8 (40960)
I0702 10:33:27.309463  7436 net.cpp:156] Memory required for data: 88316480
I0702 10:33:27.309471  7436 layer_factory.hpp:77] Creating layer relu1
I0702 10:33:27.309478  7436 net.cpp:91] Creating Layer relu1
I0702 10:33:27.309484  7436 net.cpp:425] relu1 <- ip_conv_1
I0702 10:33:27.309490  7436 net.cpp:386] relu1 -> ip_conv_1 (in-place)
I0702 10:33:27.309499  7436 net.cpp:141] Setting up relu1
I0702 10:33:27.309504  7436 net.cpp:148] Top shape: 20 32 8 8 (40960)
I0702 10:33:27.309509  7436 net.cpp:156] Memory required for data: 88480320
I0702 10:33:27.309514  7436 layer_factory.hpp:77] Creating layer drop1
I0702 10:33:27.309523  7436 net.cpp:91] Creating Layer drop1
I0702 10:33:27.309530  7436 net.cpp:425] drop1 <- ip_conv_1
I0702 10:33:27.309535  7436 net.cpp:386] drop1 -> ip_conv_1 (in-place)
I0702 10:33:27.309554  7436 net.cpp:141] Setting up drop1
I0702 10:33:27.309561  7436 net.cpp:148] Top shape: 20 32 8 8 (40960)
I0702 10:33:27.309566  7436 net.cpp:156] Memory required for data: 88644160
I0702 10:33:27.309571  7436 layer_factory.hpp:77] Creating layer ip_conv2
I0702 10:33:27.309581  7436 net.cpp:91] Creating Layer ip_conv2
I0702 10:33:27.309587  7436 net.cpp:425] ip_conv2 <- ip_conv_1
I0702 10:33:27.309593  7436 net.cpp:399] ip_conv2 -> ip_conv2
I0702 10:33:27.309725  7436 net.cpp:141] Setting up ip_conv2
I0702 10:33:27.309734  7436 net.cpp:148] Top shape: 20 2 8 8 (2560)
I0702 10:33:27.309739  7436 net.cpp:156] Memory required for data: 88654400
I0702 10:33:27.309746  7436 layer_factory.hpp:77] Creating layer upsample
I0702 10:33:27.309756  7436 net.cpp:91] Creating Layer upsample
I0702 10:33:27.309762  7436 net.cpp:425] upsample <- ip_conv2
I0702 10:33:27.309768  7436 net.cpp:399] upsample -> upsample
I0702 10:33:27.311468  7436 net.cpp:141] Setting up upsample
I0702 10:33:27.311483  7436 net.cpp:148] Top shape: 20 2 254 254 (2580640)
I0702 10:33:27.311519  7436 net.cpp:156] Memory required for data: 98976960
I0702 10:33:27.311529  7436 layer_factory.hpp:77] Creating layer loss
I0702 10:33:27.311538  7436 net.cpp:91] Creating Layer loss
I0702 10:33:27.311543  7436 net.cpp:425] loss <- upsample
I0702 10:33:27.311549  7436 net.cpp:425] loss <- label
I0702 10:33:27.311556  7436 net.cpp:399] loss -> loss
I0702 10:33:27.311571  7436 layer_factory.hpp:77] Creating layer loss
I0702 10:33:27.317736  7436 net.cpp:141] Setting up loss
I0702 10:33:27.317772  7436 net.cpp:148] Top shape: (1)
I0702 10:33:27.317778  7436 net.cpp:151]     with loss weight 1
I0702 10:33:27.317800  7436 net.cpp:156] Memory required for data: 98976964
I0702 10:33:27.317806  7436 net.cpp:217] loss needs backward computation.
I0702 10:33:27.317812  7436 net.cpp:217] upsample needs backward computation.
I0702 10:33:27.317818  7436 net.cpp:217] ip_conv2 needs backward computation.
I0702 10:33:27.317823  7436 net.cpp:217] drop1 needs backward computation.
I0702 10:33:27.317828  7436 net.cpp:217] relu1 needs backward computation.
I0702 10:33:27.317833  7436 net.cpp:217] ip_conv1 needs backward computation.
I0702 10:33:27.317838  7436 net.cpp:217] pool2 needs backward computation.
I0702 10:33:27.317843  7436 net.cpp:217] conv2 needs backward computation.
I0702 10:33:27.317848  7436 net.cpp:217] pool1 needs backward computation.
I0702 10:33:27.317862  7436 net.cpp:217] conv1 needs backward computation.
I0702 10:33:27.317868  7436 net.cpp:219] training_cells does not need backward computation.
I0702 10:33:27.317873  7436 net.cpp:261] This network produces output loss
I0702 10:33:27.317885  7436 net.cpp:274] Network initialization done.
I0702 10:33:27.318243  7436 solver.cpp:181] Creating test net (#0) specified by net file: /home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_train_test.prototxt
I0702 10:33:27.318274  7436 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer training_cells
I0702 10:33:27.318361  7436 net.cpp:49] Initializing net from parameters: 
name: "fish_filter"
state {
  phase: TEST
}
layer {
  name: "testing_cells"
  type: "Python"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  python_param {
    module: "fisherman.caffe_layers"
    layer: "ChunkingFishFovDataLayer"
    param_str: "{\'tops\': [\'image\', \'label\'], \'seed\': 1337, \'data_dir\': \'/home/sam/code/fisherman/data/dense_labelling_same_res/\', \'split\': \'test\', \'n_samples\': 5, \'chunker_params\': {\'chunk_size\': 254, \'window_size\': 1}}"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "image"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 15
    kernel_size: 15
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 5
    stride: 5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "ip_conv1"
  type: "Convolution"
  bottom: "pool2"
  top: "ip_conv_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip_conv_1"
  top: "ip_conv_1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip_conv_1"
  top: "ip_conv_1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip_conv2"
  type: "Convolution"
  bottom: "ip_conv_1"
  top: "ip_conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "upsample"
  type: "Deconvolution"
  bottom: "ip_conv2"
  top: "upsample"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: false
    kernel_size: 149
    stride: 15
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "upsample"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "upsample"
  bottom: "label"
  top: "loss"
  loss_param {
    normalize: true
  }
}
I0702 10:33:27.318768  7436 layer_factory.hpp:77] Creating layer testing_cells
I0702 10:33:27.318821  7436 net.cpp:91] Creating Layer testing_cells
I0702 10:33:27.318830  7436 net.cpp:399] testing_cells -> image
I0702 10:33:27.318840  7436 net.cpp:399] testing_cells -> label
I0702 10:33:27.336647  7436 net.cpp:141] Setting up testing_cells
I0702 10:33:27.336681  7436 net.cpp:148] Top shape: 5 2 254 254 (645160)
I0702 10:33:27.336688  7436 net.cpp:148] Top shape: 5 1 254 254 (322580)
I0702 10:33:27.336694  7436 net.cpp:156] Memory required for data: 3870960
I0702 10:33:27.336701  7436 layer_factory.hpp:77] Creating layer label_testing_cells_1_split
I0702 10:33:27.336719  7436 net.cpp:91] Creating Layer label_testing_cells_1_split
I0702 10:33:27.336724  7436 net.cpp:425] label_testing_cells_1_split <- label
I0702 10:33:27.336732  7436 net.cpp:399] label_testing_cells_1_split -> label_testing_cells_1_split_0
I0702 10:33:27.336743  7436 net.cpp:399] label_testing_cells_1_split -> label_testing_cells_1_split_1
I0702 10:33:27.336769  7436 net.cpp:141] Setting up label_testing_cells_1_split
I0702 10:33:27.336776  7436 net.cpp:148] Top shape: 5 1 254 254 (322580)
I0702 10:33:27.336782  7436 net.cpp:148] Top shape: 5 1 254 254 (322580)
I0702 10:33:27.336786  7436 net.cpp:156] Memory required for data: 6451600
I0702 10:33:27.336791  7436 layer_factory.hpp:77] Creating layer conv1
I0702 10:33:27.336803  7436 net.cpp:91] Creating Layer conv1
I0702 10:33:27.336809  7436 net.cpp:425] conv1 <- image
I0702 10:33:27.336815  7436 net.cpp:399] conv1 -> conv1
I0702 10:33:27.337039  7436 net.cpp:141] Setting up conv1
I0702 10:33:27.337050  7436 net.cpp:148] Top shape: 5 15 240 240 (4320000)
I0702 10:33:27.337055  7436 net.cpp:156] Memory required for data: 23731600
I0702 10:33:27.337065  7436 layer_factory.hpp:77] Creating layer pool1
I0702 10:33:27.337074  7436 net.cpp:91] Creating Layer pool1
I0702 10:33:27.337080  7436 net.cpp:425] pool1 <- conv1
I0702 10:33:27.337086  7436 net.cpp:399] pool1 -> pool1
I0702 10:33:27.337121  7436 net.cpp:141] Setting up pool1
I0702 10:33:27.337127  7436 net.cpp:148] Top shape: 5 15 48 48 (172800)
I0702 10:33:27.337132  7436 net.cpp:156] Memory required for data: 24422800
I0702 10:33:27.337137  7436 layer_factory.hpp:77] Creating layer conv2
I0702 10:33:27.337146  7436 net.cpp:91] Creating Layer conv2
I0702 10:33:27.337152  7436 net.cpp:425] conv2 <- pool1
I0702 10:33:27.337157  7436 net.cpp:399] conv2 -> conv2
I0702 10:33:27.337375  7436 net.cpp:141] Setting up conv2
I0702 10:33:27.337394  7436 net.cpp:148] Top shape: 5 5 42 42 (44100)
I0702 10:33:27.337399  7436 net.cpp:156] Memory required for data: 24599200
I0702 10:33:27.337407  7436 layer_factory.hpp:77] Creating layer pool2
I0702 10:33:27.337415  7436 net.cpp:91] Creating Layer pool2
I0702 10:33:27.337420  7436 net.cpp:425] pool2 <- conv2
I0702 10:33:27.337426  7436 net.cpp:399] pool2 -> pool2
I0702 10:33:27.337450  7436 net.cpp:141] Setting up pool2
I0702 10:33:27.337457  7436 net.cpp:148] Top shape: 5 5 14 14 (4900)
I0702 10:33:27.337461  7436 net.cpp:156] Memory required for data: 24618800
I0702 10:33:27.337466  7436 layer_factory.hpp:77] Creating layer ip_conv1
I0702 10:33:27.337474  7436 net.cpp:91] Creating Layer ip_conv1
I0702 10:33:27.337479  7436 net.cpp:425] ip_conv1 <- pool2
I0702 10:33:27.337530  7436 net.cpp:399] ip_conv1 -> ip_conv_1
I0702 10:33:27.337713  7436 net.cpp:141] Setting up ip_conv1
I0702 10:33:27.337723  7436 net.cpp:148] Top shape: 5 32 8 8 (10240)
I0702 10:33:27.337738  7436 net.cpp:156] Memory required for data: 24659760
I0702 10:33:27.337746  7436 layer_factory.hpp:77] Creating layer relu1
I0702 10:33:27.337752  7436 net.cpp:91] Creating Layer relu1
I0702 10:33:27.337757  7436 net.cpp:425] relu1 <- ip_conv_1
I0702 10:33:27.337764  7436 net.cpp:386] relu1 -> ip_conv_1 (in-place)
I0702 10:33:27.337770  7436 net.cpp:141] Setting up relu1
I0702 10:33:27.337775  7436 net.cpp:148] Top shape: 5 32 8 8 (10240)
I0702 10:33:27.337780  7436 net.cpp:156] Memory required for data: 24700720
I0702 10:33:27.337785  7436 layer_factory.hpp:77] Creating layer drop1
I0702 10:33:27.337792  7436 net.cpp:91] Creating Layer drop1
I0702 10:33:27.337797  7436 net.cpp:425] drop1 <- ip_conv_1
I0702 10:33:27.337803  7436 net.cpp:386] drop1 -> ip_conv_1 (in-place)
I0702 10:33:27.337819  7436 net.cpp:141] Setting up drop1
I0702 10:33:27.337826  7436 net.cpp:148] Top shape: 5 32 8 8 (10240)
I0702 10:33:27.337831  7436 net.cpp:156] Memory required for data: 24741680
I0702 10:33:27.337836  7436 layer_factory.hpp:77] Creating layer ip_conv2
I0702 10:33:27.337843  7436 net.cpp:91] Creating Layer ip_conv2
I0702 10:33:27.337848  7436 net.cpp:425] ip_conv2 <- ip_conv_1
I0702 10:33:27.337854  7436 net.cpp:399] ip_conv2 -> ip_conv2
I0702 10:33:27.337977  7436 net.cpp:141] Setting up ip_conv2
I0702 10:33:27.337985  7436 net.cpp:148] Top shape: 5 2 8 8 (640)
I0702 10:33:27.337990  7436 net.cpp:156] Memory required for data: 24744240
I0702 10:33:27.337996  7436 layer_factory.hpp:77] Creating layer upsample
I0702 10:33:27.338003  7436 net.cpp:91] Creating Layer upsample
I0702 10:33:27.338008  7436 net.cpp:425] upsample <- ip_conv2
I0702 10:33:27.338014  7436 net.cpp:399] upsample -> upsample
I0702 10:33:27.338176  7436 net.cpp:141] Setting up upsample
I0702 10:33:27.338183  7436 net.cpp:148] Top shape: 5 2 254 254 (645160)
I0702 10:33:27.338188  7436 net.cpp:156] Memory required for data: 27324880
I0702 10:33:27.338196  7436 layer_factory.hpp:77] Creating layer upsample_upsample_0_split
I0702 10:33:27.338202  7436 net.cpp:91] Creating Layer upsample_upsample_0_split
I0702 10:33:27.338207  7436 net.cpp:425] upsample_upsample_0_split <- upsample
I0702 10:33:27.338213  7436 net.cpp:399] upsample_upsample_0_split -> upsample_upsample_0_split_0
I0702 10:33:27.338219  7436 net.cpp:399] upsample_upsample_0_split -> upsample_upsample_0_split_1
I0702 10:33:27.338241  7436 net.cpp:141] Setting up upsample_upsample_0_split
I0702 10:33:27.338248  7436 net.cpp:148] Top shape: 5 2 254 254 (645160)
I0702 10:33:27.338253  7436 net.cpp:148] Top shape: 5 2 254 254 (645160)
I0702 10:33:27.338258  7436 net.cpp:156] Memory required for data: 32486160
I0702 10:33:27.338263  7436 layer_factory.hpp:77] Creating layer accuracy
I0702 10:33:27.338269  7436 net.cpp:91] Creating Layer accuracy
I0702 10:33:27.338274  7436 net.cpp:425] accuracy <- upsample_upsample_0_split_0
I0702 10:33:27.338279  7436 net.cpp:425] accuracy <- label_testing_cells_1_split_0
I0702 10:33:27.338285  7436 net.cpp:399] accuracy -> accuracy
I0702 10:33:27.338294  7436 net.cpp:141] Setting up accuracy
I0702 10:33:27.338299  7436 net.cpp:148] Top shape: (1)
I0702 10:33:27.338304  7436 net.cpp:156] Memory required for data: 32486164
I0702 10:33:27.338309  7436 layer_factory.hpp:77] Creating layer loss
I0702 10:33:27.338315  7436 net.cpp:91] Creating Layer loss
I0702 10:33:27.338320  7436 net.cpp:425] loss <- upsample_upsample_0_split_1
I0702 10:33:27.338325  7436 net.cpp:425] loss <- label_testing_cells_1_split_1
I0702 10:33:27.338330  7436 net.cpp:399] loss -> loss
I0702 10:33:27.338340  7436 layer_factory.hpp:77] Creating layer loss
I0702 10:33:27.339345  7436 net.cpp:141] Setting up loss
I0702 10:33:27.339359  7436 net.cpp:148] Top shape: (1)
I0702 10:33:27.339365  7436 net.cpp:151]     with loss weight 1
I0702 10:33:27.339375  7436 net.cpp:156] Memory required for data: 32486168
I0702 10:33:27.339407  7436 net.cpp:217] loss needs backward computation.
I0702 10:33:27.339413  7436 net.cpp:219] accuracy does not need backward computation.
I0702 10:33:27.339418  7436 net.cpp:217] upsample_upsample_0_split needs backward computation.
I0702 10:33:27.339423  7436 net.cpp:217] upsample needs backward computation.
I0702 10:33:27.339428  7436 net.cpp:217] ip_conv2 needs backward computation.
I0702 10:33:27.339433  7436 net.cpp:217] drop1 needs backward computation.
I0702 10:33:27.339438  7436 net.cpp:217] relu1 needs backward computation.
I0702 10:33:27.339442  7436 net.cpp:217] ip_conv1 needs backward computation.
I0702 10:33:27.339447  7436 net.cpp:217] pool2 needs backward computation.
I0702 10:33:27.339452  7436 net.cpp:217] conv2 needs backward computation.
I0702 10:33:27.339457  7436 net.cpp:217] pool1 needs backward computation.
I0702 10:33:27.339462  7436 net.cpp:217] conv1 needs backward computation.
I0702 10:33:27.339467  7436 net.cpp:219] label_testing_cells_1_split does not need backward computation.
I0702 10:33:27.339471  7436 net.cpp:219] testing_cells does not need backward computation.
I0702 10:33:27.339476  7436 net.cpp:261] This network produces output accuracy
I0702 10:33:27.339481  7436 net.cpp:261] This network produces output loss
I0702 10:33:27.339493  7436 net.cpp:274] Network initialization done.
I0702 10:33:27.339548  7436 solver.cpp:60] Solver scaffolding done.
I0702 10:33:27.339740  7436 caffe.cpp:219] Starting Optimization
I0702 10:33:27.339746  7436 solver.cpp:279] Solving fish_filter
I0702 10:33:27.339751  7436 solver.cpp:280] Learning Rate Policy: fixed
I0702 10:33:27.340066  7436 solver.cpp:337] Iteration 0, Testing net (#0)
I0702 10:33:27.340077  7436 net.cpp:684] Ignoring source layer training_cells
I0702 10:33:32.509986  7436 solver.cpp:404]     Test net output #0: accuracy = 0.0229265
I0702 10:33:32.510025  7436 solver.cpp:404]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0702 10:33:32.713032  7436 solver.cpp:228] Iteration 0, loss = 0.693147
I0702 10:33:32.713071  7436 solver.cpp:244]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0702 10:33:32.713080  7436 sgd_solver.cpp:106] Iteration 0, lr = 1e-07
I0702 10:33:49.668536  7436 solver.cpp:228] Iteration 20, loss = 0.693147
I0702 10:33:49.668588  7436 solver.cpp:244]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0702 10:33:49.668597  7436 sgd_solver.cpp:106] Iteration 20, lr = 1e-07
I0702 10:34:06.876948  7436 solver.cpp:228] Iteration 40, loss = 0.693147
I0702 10:34:06.877054  7436 solver.cpp:244]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0702 10:34:06.877064  7436 sgd_solver.cpp:106] Iteration 40, lr = 1e-07
I0702 10:34:24.106817  7436 solver.cpp:228] Iteration 60, loss = 0.693147
I0702 10:34:24.106853  7436 solver.cpp:244]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0702 10:34:24.106863  7436 sgd_solver.cpp:106] Iteration 60, lr = 1e-07
I0702 10:34:41.420516  7436 solver.cpp:228] Iteration 80, loss = 0.693147
I0702 10:34:41.420591  7436 solver.cpp:244]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0702 10:34:41.420600  7436 sgd_solver.cpp:106] Iteration 80, lr = 1e-07
I0702 10:34:59.344559  7436 solver.cpp:228] Iteration 100, loss = 0.693147
I0702 10:34:59.344594  7436 solver.cpp:244]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0702 10:34:59.344602  7436 sgd_solver.cpp:106] Iteration 100, lr = 1e-07
I0702 10:35:17.450582  7436 solver.cpp:228] Iteration 120, loss = 0.693147
I0702 10:35:17.450670  7436 solver.cpp:244]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0702 10:35:17.450681  7436 sgd_solver.cpp:106] Iteration 120, lr = 1e-07
I0702 10:35:35.681710  7436 solver.cpp:228] Iteration 140, loss = 0.693147
I0702 10:35:35.681743  7436 solver.cpp:244]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0702 10:35:35.681751  7436 sgd_solver.cpp:106] Iteration 140, lr = 1e-07
I0702 10:35:36.554503  7436 solver.cpp:454] Snapshotting to binary proto file fish_net_output_iter_142.caffemodel
I0702 10:35:37.239656  7436 sgd_solver.cpp:273] Snapshotting solver state to binary proto file fish_net_output_iter_142.solverstate
I0702 10:35:37.241027  7436 solver.cpp:301] Optimization stopped early.
I0702 10:35:37.241044  7436 caffe.cpp:222] Optimization Done.
