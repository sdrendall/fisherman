Log file created at: 2016/07/07 11:16:13
Running on machine: betty
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0707 11:16:13.471648  3238 caffe.cpp:185] Using GPUs 0
I0707 11:16:13.593107  3238 caffe.cpp:190] GPU 0: GeForce GTX 760
I0707 11:16:13.776522  3238 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 1000
base_lr: 0.001
display: 25
max_iter: 100000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.4
weight_decay: 0.0005
snapshot: 1000
snapshot_prefix: "fish_net_memory_map_output"
solver_mode: GPU
device_id: 0
net: "/home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_memory_map_trainer.prototxt"
I0707 11:16:13.776734  3238 solver.cpp:91] Creating training net from net file: /home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_memory_map_trainer.prototxt
I0707 11:16:13.777268  3238 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer testing_cells
I0707 11:16:13.777298  3238 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0707 11:16:13.777425  3238 net.cpp:49] Initializing net from parameters: 
name: "fish_filter"
state {
  phase: TRAIN
}
layer {
  name: "training_cells"
  type: "Python"
  top: "image"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "fisherman.caffe_layers"
    layer: "DataMapLayer"
    param_str: "{\'tops\': [\'image\', \'label\'], \'data_dir\': \'/home/sam/code/fisherman/data/dense_labelling_k149/\', \'split\': \'train\', \'samples_per_class\': 256, \'kernel\': 149}"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "image"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 15
    kernel_size: 15
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 5
    stride: 5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0707 11:16:13.777966  3238 layer_factory.hpp:77] Creating layer training_cells
I0707 11:16:14.587806  3238 net.cpp:91] Creating Layer training_cells
I0707 11:16:14.587839  3238 net.cpp:399] training_cells -> image
I0707 11:16:14.587858  3238 net.cpp:399] training_cells -> label
I0707 11:17:57.298658  3238 net.cpp:141] Setting up training_cells
I0707 11:17:57.298722  3238 net.cpp:148] Top shape: 512 2 149 149 (22733824)
I0707 11:17:57.298729  3238 net.cpp:148] Top shape: 512 (512)
I0707 11:17:57.298734  3238 net.cpp:156] Memory required for data: 90937344
I0707 11:17:57.298745  3238 layer_factory.hpp:77] Creating layer conv1
I0707 11:17:57.298768  3238 net.cpp:91] Creating Layer conv1
I0707 11:17:57.298774  3238 net.cpp:425] conv1 <- image
I0707 11:17:57.298787  3238 net.cpp:399] conv1 -> conv1
I0707 11:17:57.299911  3238 net.cpp:141] Setting up conv1
I0707 11:17:57.299937  3238 net.cpp:148] Top shape: 512 15 135 135 (139968000)
I0707 11:17:57.299943  3238 net.cpp:156] Memory required for data: 650809344
I0707 11:17:57.299957  3238 layer_factory.hpp:77] Creating layer pool1
I0707 11:17:57.299968  3238 net.cpp:91] Creating Layer pool1
I0707 11:17:57.299973  3238 net.cpp:425] pool1 <- conv1
I0707 11:17:57.299980  3238 net.cpp:399] pool1 -> pool1
I0707 11:17:57.300016  3238 net.cpp:141] Setting up pool1
I0707 11:17:57.300024  3238 net.cpp:148] Top shape: 512 15 27 27 (5598720)
I0707 11:17:57.300029  3238 net.cpp:156] Memory required for data: 673204224
I0707 11:17:57.300034  3238 layer_factory.hpp:77] Creating layer conv2
I0707 11:17:57.300043  3238 net.cpp:91] Creating Layer conv2
I0707 11:17:57.300048  3238 net.cpp:425] conv2 <- pool1
I0707 11:17:57.300055  3238 net.cpp:399] conv2 -> conv2
I0707 11:17:57.300777  3238 net.cpp:141] Setting up conv2
I0707 11:17:57.300793  3238 net.cpp:148] Top shape: 512 5 21 21 (1128960)
I0707 11:17:57.300799  3238 net.cpp:156] Memory required for data: 677720064
I0707 11:17:57.300808  3238 layer_factory.hpp:77] Creating layer pool2
I0707 11:17:57.300817  3238 net.cpp:91] Creating Layer pool2
I0707 11:17:57.300822  3238 net.cpp:425] pool2 <- conv2
I0707 11:17:57.300827  3238 net.cpp:399] pool2 -> pool2
I0707 11:17:57.300854  3238 net.cpp:141] Setting up pool2
I0707 11:17:57.300861  3238 net.cpp:148] Top shape: 512 5 7 7 (125440)
I0707 11:17:57.300866  3238 net.cpp:156] Memory required for data: 678221824
I0707 11:17:57.300871  3238 layer_factory.hpp:77] Creating layer ip1
I0707 11:17:57.300879  3238 net.cpp:91] Creating Layer ip1
I0707 11:17:57.300884  3238 net.cpp:425] ip1 <- pool2
I0707 11:17:57.300890  3238 net.cpp:399] ip1 -> ip1
I0707 11:17:57.301005  3238 net.cpp:141] Setting up ip1
I0707 11:17:57.301013  3238 net.cpp:148] Top shape: 512 32 (16384)
I0707 11:17:57.301018  3238 net.cpp:156] Memory required for data: 678287360
I0707 11:17:57.301028  3238 layer_factory.hpp:77] Creating layer relu1
I0707 11:17:57.301035  3238 net.cpp:91] Creating Layer relu1
I0707 11:17:57.301040  3238 net.cpp:425] relu1 <- ip1
I0707 11:17:57.301046  3238 net.cpp:386] relu1 -> ip1 (in-place)
I0707 11:17:57.301054  3238 net.cpp:141] Setting up relu1
I0707 11:17:57.301059  3238 net.cpp:148] Top shape: 512 32 (16384)
I0707 11:17:57.301064  3238 net.cpp:156] Memory required for data: 678352896
I0707 11:17:57.301069  3238 layer_factory.hpp:77] Creating layer drop1
I0707 11:17:57.301079  3238 net.cpp:91] Creating Layer drop1
I0707 11:17:57.301084  3238 net.cpp:425] drop1 <- ip1
I0707 11:17:57.301090  3238 net.cpp:386] drop1 -> ip1 (in-place)
I0707 11:17:57.301110  3238 net.cpp:141] Setting up drop1
I0707 11:17:57.301117  3238 net.cpp:148] Top shape: 512 32 (16384)
I0707 11:17:57.301121  3238 net.cpp:156] Memory required for data: 678418432
I0707 11:17:57.301126  3238 layer_factory.hpp:77] Creating layer ip2
I0707 11:17:57.301134  3238 net.cpp:91] Creating Layer ip2
I0707 11:17:57.301139  3238 net.cpp:425] ip2 <- ip1
I0707 11:17:57.301146  3238 net.cpp:399] ip2 -> ip2
I0707 11:17:57.301213  3238 net.cpp:141] Setting up ip2
I0707 11:17:57.301223  3238 net.cpp:148] Top shape: 512 2 (1024)
I0707 11:17:57.301226  3238 net.cpp:156] Memory required for data: 678422528
I0707 11:17:57.301234  3238 layer_factory.hpp:77] Creating layer loss
I0707 11:17:57.301240  3238 net.cpp:91] Creating Layer loss
I0707 11:17:57.301245  3238 net.cpp:425] loss <- ip2
I0707 11:17:57.301251  3238 net.cpp:425] loss <- label
I0707 11:17:57.301259  3238 net.cpp:399] loss -> loss
I0707 11:17:57.301272  3238 layer_factory.hpp:77] Creating layer loss
I0707 11:17:57.301355  3238 net.cpp:141] Setting up loss
I0707 11:17:57.301364  3238 net.cpp:148] Top shape: (1)
I0707 11:17:57.301369  3238 net.cpp:151]     with loss weight 1
I0707 11:17:57.301383  3238 net.cpp:156] Memory required for data: 678422532
I0707 11:17:57.301388  3238 net.cpp:217] loss needs backward computation.
I0707 11:17:57.301393  3238 net.cpp:217] ip2 needs backward computation.
I0707 11:17:57.301398  3238 net.cpp:217] drop1 needs backward computation.
I0707 11:17:57.301403  3238 net.cpp:217] relu1 needs backward computation.
I0707 11:17:57.301408  3238 net.cpp:217] ip1 needs backward computation.
I0707 11:17:57.301411  3238 net.cpp:217] pool2 needs backward computation.
I0707 11:17:57.301416  3238 net.cpp:217] conv2 needs backward computation.
I0707 11:17:57.301421  3238 net.cpp:217] pool1 needs backward computation.
I0707 11:17:57.301425  3238 net.cpp:217] conv1 needs backward computation.
I0707 11:17:57.301430  3238 net.cpp:219] training_cells does not need backward computation.
I0707 11:17:57.301435  3238 net.cpp:261] This network produces output loss
I0707 11:17:57.301445  3238 net.cpp:274] Network initialization done.
I0707 11:17:57.301741  3238 solver.cpp:181] Creating test net (#0) specified by net file: /home/sam/code/fisherman/caffe/fish_net/kern_149/fish_net_memory_map_trainer.prototxt
I0707 11:17:57.301767  3238 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer training_cells
I0707 11:17:57.301779  3238 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer drop1
I0707 11:17:57.301848  3238 net.cpp:49] Initializing net from parameters: 
name: "fish_filter"
state {
  phase: TEST
}
layer {
  name: "testing_cells"
  type: "Python"
  top: "image"
  top: "label"
  include {
    phase: TEST
  }
  python_param {
    module: "fisherman.caffe_layers"
    layer: "DataMapLayer"
    param_str: "{\'tops\': [\'image\', \'label\'], \'data_dir\': \'/home/sam/code/fisherman/data/dense_labelling_k149/\', \'split\': \'test\', \'samples_per_class\': 256, \'kernel\': 149}"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "image"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 15
    kernel_size: 15
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 5
    stride: 5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 5
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 3
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0707 11:17:57.302150  3238 layer_factory.hpp:77] Creating layer testing_cells
I0707 11:17:57.302196  3238 net.cpp:91] Creating Layer testing_cells
I0707 11:17:57.302203  3238 net.cpp:399] testing_cells -> image
I0707 11:17:57.302237  3238 net.cpp:399] testing_cells -> label
I0707 11:18:46.177088  3238 net.cpp:141] Setting up testing_cells
I0707 11:18:46.177167  3238 net.cpp:148] Top shape: 512 2 149 149 (22733824)
I0707 11:18:46.177182  3238 net.cpp:148] Top shape: 512 (512)
I0707 11:18:46.177187  3238 net.cpp:156] Memory required for data: 90937344
I0707 11:18:46.177196  3238 layer_factory.hpp:77] Creating layer label_testing_cells_1_split
I0707 11:18:46.177215  3238 net.cpp:91] Creating Layer label_testing_cells_1_split
I0707 11:18:46.177222  3238 net.cpp:425] label_testing_cells_1_split <- label
I0707 11:18:46.177230  3238 net.cpp:399] label_testing_cells_1_split -> label_testing_cells_1_split_0
I0707 11:18:46.177242  3238 net.cpp:399] label_testing_cells_1_split -> label_testing_cells_1_split_1
I0707 11:18:46.177274  3238 net.cpp:141] Setting up label_testing_cells_1_split
I0707 11:18:46.177283  3238 net.cpp:148] Top shape: 512 (512)
I0707 11:18:46.177287  3238 net.cpp:148] Top shape: 512 (512)
I0707 11:18:46.177292  3238 net.cpp:156] Memory required for data: 90941440
I0707 11:18:46.177297  3238 layer_factory.hpp:77] Creating layer conv1
I0707 11:18:46.177309  3238 net.cpp:91] Creating Layer conv1
I0707 11:18:46.177314  3238 net.cpp:425] conv1 <- image
I0707 11:18:46.177321  3238 net.cpp:399] conv1 -> conv1
I0707 11:18:46.177518  3238 net.cpp:141] Setting up conv1
I0707 11:18:46.177528  3238 net.cpp:148] Top shape: 512 15 135 135 (139968000)
I0707 11:18:46.177533  3238 net.cpp:156] Memory required for data: 650813440
I0707 11:18:46.177546  3238 layer_factory.hpp:77] Creating layer pool1
I0707 11:18:46.177553  3238 net.cpp:91] Creating Layer pool1
I0707 11:18:46.177559  3238 net.cpp:425] pool1 <- conv1
I0707 11:18:46.177566  3238 net.cpp:399] pool1 -> pool1
I0707 11:18:46.177592  3238 net.cpp:141] Setting up pool1
I0707 11:18:46.177598  3238 net.cpp:148] Top shape: 512 15 27 27 (5598720)
I0707 11:18:46.177603  3238 net.cpp:156] Memory required for data: 673208320
I0707 11:18:46.177608  3238 layer_factory.hpp:77] Creating layer conv2
I0707 11:18:46.177618  3238 net.cpp:91] Creating Layer conv2
I0707 11:18:46.177623  3238 net.cpp:425] conv2 <- pool1
I0707 11:18:46.177629  3238 net.cpp:399] conv2 -> conv2
I0707 11:18:46.177778  3238 net.cpp:141] Setting up conv2
I0707 11:18:46.177785  3238 net.cpp:148] Top shape: 512 5 21 21 (1128960)
I0707 11:18:46.177790  3238 net.cpp:156] Memory required for data: 677724160
I0707 11:18:46.177799  3238 layer_factory.hpp:77] Creating layer pool2
I0707 11:18:46.177805  3238 net.cpp:91] Creating Layer pool2
I0707 11:18:46.177811  3238 net.cpp:425] pool2 <- conv2
I0707 11:18:46.177817  3238 net.cpp:399] pool2 -> pool2
I0707 11:18:46.177840  3238 net.cpp:141] Setting up pool2
I0707 11:18:46.177848  3238 net.cpp:148] Top shape: 512 5 7 7 (125440)
I0707 11:18:46.177853  3238 net.cpp:156] Memory required for data: 678225920
I0707 11:18:46.177857  3238 layer_factory.hpp:77] Creating layer ip1
I0707 11:18:46.177866  3238 net.cpp:91] Creating Layer ip1
I0707 11:18:46.177870  3238 net.cpp:425] ip1 <- pool2
I0707 11:18:46.177877  3238 net.cpp:399] ip1 -> ip1
I0707 11:18:46.177983  3238 net.cpp:141] Setting up ip1
I0707 11:18:46.177992  3238 net.cpp:148] Top shape: 512 32 (16384)
I0707 11:18:46.177997  3238 net.cpp:156] Memory required for data: 678291456
I0707 11:18:46.178005  3238 layer_factory.hpp:77] Creating layer relu1
I0707 11:18:46.178012  3238 net.cpp:91] Creating Layer relu1
I0707 11:18:46.178017  3238 net.cpp:425] relu1 <- ip1
I0707 11:18:46.178023  3238 net.cpp:386] relu1 -> ip1 (in-place)
I0707 11:18:46.178030  3238 net.cpp:141] Setting up relu1
I0707 11:18:46.178036  3238 net.cpp:148] Top shape: 512 32 (16384)
I0707 11:18:46.178041  3238 net.cpp:156] Memory required for data: 678356992
I0707 11:18:46.178045  3238 layer_factory.hpp:77] Creating layer ip2
I0707 11:18:46.178053  3238 net.cpp:91] Creating Layer ip2
I0707 11:18:46.178058  3238 net.cpp:425] ip2 <- ip1
I0707 11:18:46.178066  3238 net.cpp:399] ip2 -> ip2
I0707 11:18:46.178120  3238 net.cpp:141] Setting up ip2
I0707 11:18:46.178128  3238 net.cpp:148] Top shape: 512 2 (1024)
I0707 11:18:46.178133  3238 net.cpp:156] Memory required for data: 678361088
I0707 11:18:46.178139  3238 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0707 11:18:46.178175  3238 net.cpp:91] Creating Layer ip2_ip2_0_split
I0707 11:18:46.178181  3238 net.cpp:425] ip2_ip2_0_split <- ip2
I0707 11:18:46.178187  3238 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0707 11:18:46.178194  3238 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0707 11:18:46.178218  3238 net.cpp:141] Setting up ip2_ip2_0_split
I0707 11:18:46.178225  3238 net.cpp:148] Top shape: 512 2 (1024)
I0707 11:18:46.178231  3238 net.cpp:148] Top shape: 512 2 (1024)
I0707 11:18:46.178236  3238 net.cpp:156] Memory required for data: 678369280
I0707 11:18:46.178241  3238 layer_factory.hpp:77] Creating layer accuracy
I0707 11:18:46.178251  3238 net.cpp:91] Creating Layer accuracy
I0707 11:18:46.178256  3238 net.cpp:425] accuracy <- ip2_ip2_0_split_0
I0707 11:18:46.178261  3238 net.cpp:425] accuracy <- label_testing_cells_1_split_0
I0707 11:18:46.178267  3238 net.cpp:399] accuracy -> accuracy
I0707 11:18:46.178277  3238 net.cpp:141] Setting up accuracy
I0707 11:18:46.178282  3238 net.cpp:148] Top shape: (1)
I0707 11:18:46.178287  3238 net.cpp:156] Memory required for data: 678369284
I0707 11:18:46.178292  3238 layer_factory.hpp:77] Creating layer loss
I0707 11:18:46.178297  3238 net.cpp:91] Creating Layer loss
I0707 11:18:46.178303  3238 net.cpp:425] loss <- ip2_ip2_0_split_1
I0707 11:18:46.178308  3238 net.cpp:425] loss <- label_testing_cells_1_split_1
I0707 11:18:46.178313  3238 net.cpp:399] loss -> loss
I0707 11:18:46.178323  3238 layer_factory.hpp:77] Creating layer loss
I0707 11:18:46.178371  3238 net.cpp:141] Setting up loss
I0707 11:18:46.178378  3238 net.cpp:148] Top shape: (1)
I0707 11:18:46.178383  3238 net.cpp:151]     with loss weight 1
I0707 11:18:46.178393  3238 net.cpp:156] Memory required for data: 678369288
I0707 11:18:46.178398  3238 net.cpp:217] loss needs backward computation.
I0707 11:18:46.178405  3238 net.cpp:219] accuracy does not need backward computation.
I0707 11:18:46.178409  3238 net.cpp:217] ip2_ip2_0_split needs backward computation.
I0707 11:18:46.178414  3238 net.cpp:217] ip2 needs backward computation.
I0707 11:18:46.178419  3238 net.cpp:217] relu1 needs backward computation.
I0707 11:18:46.178423  3238 net.cpp:217] ip1 needs backward computation.
I0707 11:18:46.178428  3238 net.cpp:217] pool2 needs backward computation.
I0707 11:18:46.178433  3238 net.cpp:217] conv2 needs backward computation.
I0707 11:18:46.178438  3238 net.cpp:217] pool1 needs backward computation.
I0707 11:18:46.178443  3238 net.cpp:217] conv1 needs backward computation.
I0707 11:18:46.178448  3238 net.cpp:219] label_testing_cells_1_split does not need backward computation.
I0707 11:18:46.178454  3238 net.cpp:219] testing_cells does not need backward computation.
I0707 11:18:46.178458  3238 net.cpp:261] This network produces output accuracy
I0707 11:18:46.178463  3238 net.cpp:261] This network produces output loss
I0707 11:18:46.178474  3238 net.cpp:274] Network initialization done.
I0707 11:18:46.178524  3238 solver.cpp:60] Solver scaffolding done.
I0707 11:18:46.178685  3238 caffe.cpp:209] Resuming from fish_net_memory_map_output_iter_3060.solverstate
I0707 11:18:46.178951  3238 sgd_solver.cpp:318] SGDSolver: restoring history
I0707 11:18:46.179044  3238 caffe.cpp:219] Starting Optimization
I0707 11:18:46.179050  3238 solver.cpp:279] Solving fish_filter
I0707 11:18:46.179055  3238 solver.cpp:280] Learning Rate Policy: inv
I0707 11:21:19.270051  3238 solver.cpp:228] Iteration 3075, loss = 0.414006
I0707 11:21:19.270143  3238 solver.cpp:244]     Train net output #0: loss = 0.414006 (* 1 = 0.414006 loss)
I0707 11:21:19.270156  3238 sgd_solver.cpp:106] Iteration 3075, lr = 0.000817841
I0707 11:25:23.369693  3238 solver.cpp:228] Iteration 3100, loss = 0.374143
I0707 11:25:23.369789  3238 solver.cpp:244]     Train net output #0: loss = 0.374143 (* 1 = 0.374143 loss)
I0707 11:25:23.369801  3238 sgd_solver.cpp:106] Iteration 3100, lr = 0.00081667
I0707 11:29:13.456225  3238 solver.cpp:228] Iteration 3125, loss = 0.423244
I0707 11:29:13.456302  3238 solver.cpp:244]     Train net output #0: loss = 0.423244 (* 1 = 0.423244 loss)
I0707 11:29:13.456315  3238 sgd_solver.cpp:106] Iteration 3125, lr = 0.000815503
I0707 11:33:12.559047  3238 solver.cpp:228] Iteration 3150, loss = 0.386107
I0707 11:33:12.559135  3238 solver.cpp:244]     Train net output #0: loss = 0.386107 (* 1 = 0.386107 loss)
I0707 11:33:12.559151  3238 sgd_solver.cpp:106] Iteration 3150, lr = 0.00081434
I0707 11:35:59.062012  3238 solver.cpp:454] Snapshotting to binary proto file fish_net_memory_map_output_iter_3169.caffemodel
I0707 11:36:00.104324  3238 sgd_solver.cpp:273] Snapshotting solver state to binary proto file fish_net_memory_map_output_iter_3169.solverstate
I0707 11:36:00.104691  3238 solver.cpp:301] Optimization stopped early.
I0707 11:36:00.104714  3238 caffe.cpp:222] Optimization Done.
